{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/sustaingym\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE    algo_comp_2021.png  env_norl.yml\t examples   sustaingym\n",
      "README.md  env.yml\t       epsiode_plot.png  notebooks\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n",
      "/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import stable_baselines3 as sb3\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sustaingym.envs import ElectricityMarketEnv\n",
    "from sustaingym.envs.battery.plot_utils import *\n",
    "from sustaingym.envs.battery.wrapped import DiscreteActions\n",
    "from sustaingym.evaluate.run_electricitymarket import *\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ElectricityMarketEnv(month='2021-05', seed=215, use_intermediate_rewards=True)\n",
    "discrete_env = DiscreteActions(env)\n",
    "reset_seed = 15\n",
    "seeds = np.arange(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run offline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01548457145690918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 30,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb94fa6c584d467f84be3f6f2625d9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt_results = run_offline_optimal(seeds, env)\n",
    "save_results(opt_results, seeds=seeds, path='examples/intermreward/offline_results.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015914440155029297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 30,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab2726511b64edcafef316f18455832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt_results = np.load('examples/intermreward/offline_results.npz')\n",
    "follow_results = run_follow_offline_optimal(\n",
    "    seeds, env,\n",
    "    opt_dispatches=opt_results['dispatch'],\n",
    "    opt_energies=opt_results['energy'])\n",
    "save_results(follow_results, seeds=seeds, path='examples/intermreward/follow_offline_results.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015996694564819336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 30,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae899bfc53e4bc69f056c884736277e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = run_random(seeds, env, discrete=False)\n",
    "save_results(results, seeds=seeds, path='examples/intermreward/random_results.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016693115234375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 30,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c4995f648a44e898061a1567bb3954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = run_random(seeds, discrete_env, discrete=True)\n",
    "save_results(results, seeds=seeds, path='examples/intermreward/random_discrete_results.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO Models\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions, intermediate rewards, and learning rate of 0.003\n",
    "%run examples/train -y 2019 -v 2021 -a -i -m PPO -l 0.003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions, intermediate rewards, and learning rate of 0.0003\n",
    "%run examples/train -y 2019 -v 2021 -a -i -m PPO -l 0.0003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions, intermediate rewards, and learning rate of 3e-05\n",
    "%run examples/train -y 2019 -v 2021 -a -i -m PPO -l 3e-05 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions, intermediate rewards, and learning rate of 0.003\n",
    "%run examples/train -y 2021 -a -i -m PPO -l 0.003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions, intermediate rewards, and learning rate of 0.0003\n",
    "%run examples/train -y 2021 -a -i -m PPO -l 0.0003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions, intermediate rewards, and learning rate of 3e-05\n",
    "%run examples/train -y 2021 -a -i -m PPO -l 3e-05 -o examples/intermreward\n",
    "\n",
    "\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with discrete actions, saved actions, intermediate rewards, and learning rate of 0.003\n",
    "%run examples/train -y 2019 -v 2021 -d -a -i -m PPO -l 0.003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with discrete actions, saved actions, intermediate rewards, and learning rate of 0.0003\n",
    "%run examples/train -y 2019 -v 2021 -d -a -i -m PPO -l 0.0003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with discrete actions, saved actions, intermediate rewards, and learning rate of 3e-05\n",
    "%run examples/train -y 2019 -v 2021 -d -a -i -m PPO -l 3e-05 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with discrete actions, saved actions, intermediate rewards, and learning rate of 0.003\n",
    "%run examples/train -y 2021 -d -a -i -m PPO -l 0.003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with discrete actions, saved actions, intermediate rewards, and learning rate of 0.0003\n",
    "%run examples/train -y 2021 -d -a -i -m PPO -l 0.0003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with discrete actions, saved actions, intermediate rewards, and learning rate of 3e-05\n",
    "%run examples/train -y 2021 -d -a -i -m PPO -l 3e-05 -o examples/intermreward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAC Models\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions, intermediate rewards, and learning rate of 0.003\n",
    "%run examples/train -y 2019 -v 2021 -a -i -m SAC -l 0.003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions, intermediate rewards, and learning rate of 0.0003\n",
    "%run examples/train -y 2019 -v 2021 -a -i -m SAC -l 0.0003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions, intermediate rewards, and learning rate of 3e-05\n",
    "%run examples/train -y 2019 -v 2021 -a -i -m SAC -l 3e-05 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions, intermediate rewards, and learning rate of 0.003\n",
    "%run examples/train -y 2021 -a -i -m SAC -l 0.003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions, intermediate rewards, and learning rate of 0.0003\n",
    "%run examples/train -y 2021 -a -i -m SAC -l 0.0003 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions, intermediate rewards, and learning rate of 3e-05\n",
    "%run examples/train -y 2021 -a -i -m SAC -l 3e-05 -o examples/intermreward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Models\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions, intermediate rewards, and learning rate of 0.001\n",
    "%run examples/train -y 2019 -v 2021 -d -a -i -m DQN -l 0.001 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions, intermediate rewards, and learning rate of 0.0001\n",
    "%run examples/train -y 2019 -v 2021 -d -a -i -m DQN -l 0.0001 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions, intermediate rewards, and learning rate of 1e-05\n",
    "%run examples/train -y 2019 -v 2021 -d -a -i -m DQN -l 1e-05 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions, intermediate rewards, and learning rate of 0.001\n",
    "%run examples/train -y 2021 -d -a -i -m DQN -l 0.001 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions, intermediate rewards, and learning rate of 0.0001\n",
    "%run examples/train -y 2021 -d -a -i -m DQN -l 0.0001 -o examples/intermreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions, intermediate rewards, and learning rate of 1e-5\n",
    "%run examples/train -y 2021 -d -a -i -m DQN -l 1e-05 -o examples/intermreward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run RL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best PPO 2019 model\n",
    "for model_name in ['PPO_2019_g0.9999_lr0.003', 'PPO_2019_g0.9999_lr0.0003', 'PPO_2019_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/intermreward/{model_name}/eval2019/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(\"model: \", model_name)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best PPO 2021 model\n",
    "for model_name in ['PPO_2021_g0.9999_lr0.003', 'PPO_2021_g0.9999_lr0.0003', 'PPO_2021_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/intermreward/{model_name}/eval2021/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(\"model: \", model_name)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best PPO discrete 2019 model\n",
    "for model_name in ['PPO_discrete_2019_g0.9999_lr0.003', 'PPO_discrete_2019_g0.9999_lr0.0003', 'PPO_discrete_2019_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/intermreward/{model_name}/eval2019/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(\"model: \", model_name)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best PPO discrete 2021 model\n",
    "for model_name in ['PPO_discrete_2021_g0.9999_lr0.003', 'PPO_discrete_2021_g0.9999_lr0.0003', 'PPO_discrete_2021_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/intermreward/{model_name}/eval2021/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(\"model: \", model_name)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best SAC 2019 model\n",
    "for model_name in ['SAC_2019_g0.9999_lr0.003', 'SAC_2019_g0.9999_lr0.0003', 'SAC_2019_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/intermreward/{model_name}/eval2019/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(\"model: \", model_name)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best SAC 2021 model\n",
    "for model_name in ['SAC_2021_g0.9999_lr0.003', 'SAC_2021_g0.9999_lr0.0003', 'SAC_2021_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/intermreward/{model_name}/eval2021/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best DQN 2019 model\n",
    "for model_name in ['DQN_discrete_2019_g0.9999_lr0.001', 'DQN_discrete_2019_g0.9999_lr0.0001', 'DQN_discrete_2019_g0.9999_lr1e-05']:\n",
    "    evals_path = f'examples/intermreward/{model_name}/eval2019/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best DQN 2021 model\n",
    "for model_name in ['DQN_discrete_2021_g0.9999_lr0.001', 'DQN_discrete_2021_g0.9999_lr0.0001', 'DQN_discrete_2021_g0.9999_lr1e-05']:\n",
    "    evals_path = f'examples/intermreward/{model_name}/eval2021/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo2019_model_dir = 'examples/intermreward/PPO_2019_g0.9999_lr0.0003/'\n",
    "ppo2021_model_dir = 'examples/intermreward/PPO_2021_g0.9999_lr0.0003/'\n",
    "ppodiscrete2019_model_dir = 'examples/intermreward/PPO_discrete_2019_g0.9999_lr0.0003/'\n",
    "ppodiscrete2021_model_dir = 'examples/intermreward/PPO_discrete_2021_g0.9999_lr0.0003/'\n",
    "sac2019_model_dir = 'examples/intermreward/SAC_2019_g0.9999_lr3e-05/'\n",
    "sac2021_model_dir = 'examples/intermreward/SAC_2021_g0.9999_lr0.0003/'\n",
    "dqn2019_model_dir = 'examples/intermreward/DQN_discrete_2019_g0.9999_lr1e-05/'\n",
    "dqn2021_model_dir = 'examples/intermreward/DQN_discrete_2021_g0.9999_lr0.0001/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo2019 = sb3.PPO.load(os.path.join(ppo2019_model_dir, 'eval2019/best_model.zip'))\n",
    "results = run_model(ppo2019, seeds=seeds, env=env, discrete=False)\n",
    "save_results(results, seeds=seeds, path=os.path.join(ppo2019_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo2021 = sb3.PPO.load(os.path.join(ppo2021_model_dir, 'eval2021/best_model.zip'))\n",
    "results = run_model(ppo2021, seeds=seeds, env=env, discrete=False)\n",
    "save_results(results, seeds=seeds, path=os.path.join(ppo2021_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppodiscrete2019 = sb3.PPO.load(os.path.join(ppodiscrete2019_model_dir, 'eval2019/best_model.zip'))\n",
    "results = run_model(ppodiscrete2019, seeds=seeds, env=discrete_env, discrete=True)\n",
    "save_results(results, seeds=seeds, path=os.path.join(ppodiscrete2019_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppodiscrete2021 = sb3.PPO.load(os.path.join(ppodiscrete2021_model_dir, 'eval2021/best_model.zip'))\n",
    "results = run_model(ppodiscrete2021, seeds=seeds, env=discrete_env, discrete=True)\n",
    "save_results(results, seeds=seeds, path=os.path.join(ppodiscrete2021_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac2019 = sb3.SAC.load(os.path.join(sac2019_model_dir, 'eval2019/best_model.zip'))\n",
    "results = run_model(sac2019, seeds=seeds, env=env, discrete=False)\n",
    "save_results(results, seeds=seeds, path=os.path.join(sac2019_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac2021 = sb3.SAC.load(os.path.join(sac2021_model_dir, 'model.zip'))\n",
    "results = run_model(sac2021, seeds=seeds, env=env, discrete=False)\n",
    "save_results(results, seeds=seeds, path=os.path.join(sac2021_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn2019 = sb3.DQN.load(os.path.join(dqn2019_model_dir, 'eval2019/best_model.zip'))\n",
    "results = run_model(dqn2019, seeds=seeds, env=discrete_env, discrete=True)\n",
    "save_results(results, seeds=seeds, path=os.path.join(dqn2019_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn2021 = sb3.DQN.load(os.path.join(dqn2021_model_dir, 'model.zip'))\n",
    "results = run_model(dqn2021, seeds=seeds, env=discrete_env, discrete=True)\n",
    "save_results(results, seeds=seeds, path=os.path.join(dqn2021_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results and make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_paths = {\n",
    "    'oracle': 'examples/intermreward/offline_results.npz',\n",
    "    'follow oracle': 'examples/intermreward/follow_offline_results.npz',\n",
    "    'rand': 'examples/intermreward/random_results.npz',\n",
    "    'rand discrete': 'examples/intermreward/random_discrete_results.npz',\n",
    "\n",
    "    'PPO (2019)': os.path.join(ppo2019_model_dir, 'eval2021/results.npz'),\n",
    "    'PPO (2021)': os.path.join(ppo2021_model_dir, 'eval2021/results.npz'),\n",
    "    'PPO discrete (2019)': os.path.join(ppodiscrete2019_model_dir, 'eval2021/results.npz'),\n",
    "    'PPO discrete (2021)': os.path.join(ppodiscrete2021_model_dir, 'eval2021/results.npz'),\n",
    "    'SAC (2019)': os.path.join(sac2019_model_dir, 'eval2021/results.npz'),\n",
    "    'SAC (2021)': os.path.join(sac2021_model_dir, 'eval2021/results.npz'),\n",
    "    'DQN (2019)': os.path.join(dqn2019_model_dir, 'eval2021/results.npz'),\n",
    "    'DQN (2021)': os.path.join(dqn2021_model_dir, 'eval2021/results.npz')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {label: np.load(path) for label, path in results_paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_returns(results, ylim=(-16000, 3000))\n",
    "fig.savefig('plots/em_returns.png', dpi=300, pad_inches=0, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 13\n",
    "ep_data = {}\n",
    "for label, d in results.items():\n",
    "    data = {k: d[k][seed] for k in ['rewards', 'prices', 'energy']}\n",
    "    data['model_name'] = label\n",
    "    if 'SAC (2021)' in label:\n",
    "        data['bids'] = d['actions'][seed]\n",
    "    ep_data[label] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset(seed)\n",
    "fig, axs, times = setup_episode_plot(env, '2021-05', include_returns=True, include_bids=True)\n",
    "for label in ['oracle', 'follow oracle', 'rand', 'rand discrete', 'SAC (2021)', 'DQN (2021)', 'PPO discrete (2021)']:\n",
    "    plot_episode(axs, times, **ep_data[label])\n",
    "\n",
    "for plot in ['prices', 'energy', 'rewards', 'bids']:\n",
    "    axs[plot].legend(bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('plots/em_episode.png', dpi=300, pad_inches=0, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sustaingym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c910351b0c3a4aade2cf03b555240fe9951314ae7b50b4f56bc279231ceafe8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
