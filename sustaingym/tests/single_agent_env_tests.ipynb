{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:272: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing environment with stable_baselines3 library\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from envs.MO_single_agent_battery_storage_env import BatteryStorageInGridEnv\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnt0lEQVR4nO3df7xVVZ3/8dcb8NcE/kCBIRCx0RLRIiTUqXF0iESn0RIlyFFMGorRb6ZNhU191RodnW/mjyzLRkc0NZ2mBqeUUqycJoFQURFzxMJEbwj+QLA0wM/3j7WObC7n3n3uj3Pugft+Ph7ncfdZ+9fa565zPnuvvfZaigjMzMza06enM2BmZs3PwcLMzEo5WJiZWSkHCzMzK+VgYWZmpRwszMyslIPFNkjS+ZK+3dP56ChJ6yW9pafzYfWl5N8kvShpUU6bJWlVLgN7SgpJ++V535D0hZ7Nde3qmd/i59JsHCy6iaQVkv6Qvwy/k3S9pP49na/uIGlfSa9L+noH1vmppI8W0yKif0T8uvtzaI0k6TRJj0j6fS7rV0vavbDIe4CJwPCIGC9pB+ArwPtyGXi+uL2I+HhEfKlOeR0u6SZJz0t6RdIiSe/vwPqnSfp5Ma2e+W1mDhbd628ioj8wBngncG7PZqfbnAq8CEyVtFNPZ8Z6jqRPAZcAnwZ2Aw4D9gHukrRjXmwfYEVEvJLfDwF2Bh5tcF4HAj8H/giMBvYCLgNulnRiI/OyXYgIv7rhBawA3lt4/y/ADwvvZwNPAuuAZcAHC/NOIxXqL5N+lH8DHFOYvy/ws7zuXcBVwLcL848jfRFfAn4KjGqVr08DDwOvANeSvrx35u3dDexRcmxPArOAVcCJreYdDywBXs7LTQIuBDYBrwLrgavysgHsl6d3A24AVgNPAZ8H+tT4eZwG/Drn/zfAyT39/+8NL2DX/P+c0iq9P/AccDowI//fN+Vlb8nlLvL7e6qUheuBf8rTRwIrgU/lbbYAHynsa6dcLn6by+M3gF3ayO+XgKWVclVI/2wucyrk5RO5TK0B/h/pRHpUq2N5qZ38fqaQ3w8AxwL/C7wAfK6w7/HAfaTvagvpu7xjYf4bn0uzvXo8A9vLi0KwAIYDjwBXFOafBLw5F8IP5S/Q0DzvNGAD8HdAX9IP87OFwnwf6TJ+J+CI/CP57TzvrXlbE4EdcqFdXimAOV8LSAFiWC7QD5CufHYC7gHOa+e4/gJ4DdgD+Cpwe2HeeGBt3nefvP0D8ryfAh9tta3iD8QNwFxgADAyf7FmlH0ewJtIgeltedmhwOie/v/3hhfpRGAj0K/KvDnALYX/388L80bm/32/Qlp7wWIj8MVcno8Ffk8+oQEuB24HBuay81/AP7eR3wXABVXS9837f1shLz/J2xyRy+JHqx1LO/n9vzm/f0c6Abo55280KeC8JS9/COlqrF/+XB4DPlntc2m2l6uhutd/SloHPE36UT6vMiMi/j0ino2I1yPiVuAJ0o9txVMR8a2I2ET64g0FhkgaAbwL+EJEvBYR95K+IBUfIl3B3BURG0hnXbsAf15Y5qsRsSoingH+G1gYEQ9GxGvA90mBoy3TgTsj4kXSF+AYSYPzvBnAdXnfr0fEMxHxq7IPSVLfnO9zI2JdRKwALgVOKfs88rzXgYMk7RIRLRHR0OqNXmwvYE1EbKwyryXP7w4bgC9GxIaIuIN0Vv82SSL9GJ8dES9ExDrgImBqO/ltaSOvlfkVl+Rt/pYUkKZ1ML8X5u/fd/J2r8hl+1HSVf/bASLi/ohYEBEbc7n/JvCXHdhXj3Gw6F4fiIgBpLONAygURkmnSloi6SVJLwEHsWVh/V1lIiJ+nyf7k65GXozN9b+QLqEr3lx8HxGvk4LVsMIyqwrTf6jyvuqNeEm7kK6Ibsrbvo90+f/hvMjepKqnjtoL2LHVcTzVKs9VP4/8OXwI+DjQIumHkg7oRB6s49YAe0nqV2Xe0Dy/OzzfKiD9nlRGBwF/Atxf+B7Ny+lt5XdoG3mtzK94ujD9FOl71ZH8bsrTf8h/q37HJL1V0g9yw4CXScGuu4JsXTlY1EFE/Ix0qfplAEn7AN8CzgT2jIjdSXWpqmFzLcAekt5USBtRmH6WdEORvC+RfsSf6fwRvOGDpHrqr+fC/TvSD/qpef7TwJ+1sW573RmvIZ2N7VNIG0GNeY6IH0XERNKX/lekz9bq7z5SleQJxcRcNo8B5td5/2tIP7yjI2L3/NotUqOSau4GJktq/Ts3hVR2/7eQtndhegTpewXtl+POuJpUZvePiF2Bz1Hb70CPc7Con8uBiZLGkOrZg1SXiaSPkK4sSkXEU8Bi4AJJO0p6D/A3hUVuA/5a0oTcRPFTpC/0L7rhGKYD1wEHk1p4jQHeDYyRdDDpZvlH8r77SBpWOMtfBVR9piKfhd0GXChpQA6m5wClz45IGiLpuPwD9RqpimJTyWrWDSJiLXAB8FVJkyTtIGkk8O+km7w31nn/r5NODC6rVIXmMnd0G6tcRjrZuVbSn0raWdI04B+BT0e+SZB9WtIekvYGzgJuzemrgOGFll5dNYB0z219/q7M6qbt1p2DRZ1ExGrSTdwvRMQyUp38faTCdzDwPx3Y3IeBQ0ktK87L263s53Hgb0k3n9eQAsnfRMQfu5J/ScOACcDlEfG7wut+0qX/9IhYBHyE9KVcS2qxVblauAI4MT+YdWWVXfwf0o35X5NaPt1MCkxl+pAC4rOkz+Mvgb/v5GFaB0XEv5DOhr9M+tFbSDpLn5DvgdXbZ0kNOBbkapy7gbe1kdfnSc987Exqgfg86aTklHzfsGgucD+pZd8PSSdCkBqAPAr8TlJ3VLP9A+n7vI4U+Frno2lpy+BqZta7SApStdDyns5LM/OVhZmZlXKwMDOzUq6GMjOzUr6yMDOzUtUertku7LXXXjFy5MiezoZtp+6///41EdHWw2B143Jt9dReua5bsJC0M3Avqf+hfsB3I+I8Seezuf8USJ1s3ZHXOZfUhcQm4BMR8aOcfgjpIbddgDuAs6Kk/mzkyJEsXry4uw/LDABJT5Uv1f1crq2e2ivX9byyeA34q4hYnx8W+7mkO/O8yyLiy60yeSCpj5fRpEft75b01vwA19XATFLHYHeQOjS7EzMza4i63bOIZH1+u0N+tXc1cDzwndxZ3m9ID96MlzQU2DUi7stXEzeQugA2M7MGqesNbkl9JS0h9cB6V0QszLPOlPSwpOsk7ZHThrFlZ14rc9qwPN06vdr+ZkpaLGnx6tWrqy1iZmadUNdgERGbImIMaXyH8ZIOIlUp/Rmpn6EWUjcYUL0zrWgnvdr+romIcRExbtCght97NDPbbjWk6WxEvEQaDGdSHldhU6FTsMqYDivZsufH4aT+f1bm6dbpZmbWIHULFpIGVQZxz+MivBf4Vb4HUfFBUlfdkEa/mippJ0n7AvsDiyKiBVgn6bDc/fappE6/zMysQerZGmooMCePitYHuC0ifiDpxtxtd5CG/PwYQEQ8Kuk2Uu+QG4EzCgOKzGJz09k7cUsoM7OGqluwiIiHqTJcZ0ScUmXxyrwLgQurpC+mxvEfzMys+7m7DzMzK7XddvdhMHL2D9uct+Liv25gTsyag78Tndcrg0VnC4wLWn31xOfr/6lZbVwNZWZmpRwszMysVK+shrL6cbWO2fbJVxZmZlbKwcLMzEo5WJhVERv/yPjx43nHO97B6NGjOe+88wB44YUXmDhxIsBBku4q9JqMpHMlLZf0uKSjC+mHSHokz7syd1tD7trm1py+UNLIxh6lWe0cLMyq6bsD99xzDw899BBLlixh3rx5LFiwgIsvvpgJEyZA6tNsPjAbthq8axLw9dzVDWwevGv//JqU02cAL0bEfsBlwCUNOjqzDnOwMKtCEv379wdgw4YNbNiwAUnMnTuX6dOnVxabw+aBuDozeNfxeRsA3wUmVK46zJqNg4VZGzZt2sSYMWMYPHgwEydO5NBDD2XVqlUMHZo6Ts49Ig/Oi3dm8K431omIjcBaYM/W+fCgXtYMHCzM2tC3b1+WLFnCypUrWbRoEUuXLm1v8c4M3lXTwF4e1MuagYOFWYndd9+dI488knnz5jFkyBBaWloAyFVMz+XFOjN41xvrSOoH7Aa8UK/jMOsKBwuzKjb9fi0vvfQSAH/4wx+4++67OeCAAzjuuOOYM6dym4HpbB6IqzODd92etwFwInBPvq9h1nT8BLdZFZvWv8BRRx3Fpk2beP3115kyZQrvf//7Ofzww5kyZQqk8VXWAidBpwfvuha4UdJy0hXF1AYdnlmHOViYVbHj4H158MEHt0rfc889mT9/PpKWRsSE4ryODt4VEa+Sg41Zs3M1lJmZlXKwMDOzUq6Gsm2ee7o1qz9fWZiZWam6XVlI2hm4F9gp7+e7EXGepIHArcBIYAUwJSJezOucS+ovZxPwiYj4UU4/hM2tSe4AztrWmhj67NfMtmX1vLJ4DfiriHgHMAaYJOkwUsdr8yNif7reEZuZmTVA3YJFJOvz2x3yK9iy87SudsRmZmYNUNcb3PnK4H5gP+BrEbFQ0pD8VCsR0SKp2BHbgsLqlQ7XNtB2R2yt9zeTdAXCiBEjuvNQekx71VfgKiwza4y63uCOiE0RMYbUH854SVs9mFTQmY7YWu/PHa6ZmdVBQ1pDRcRLwE9J9xpW5aql7uiIzczMGqBuwULSIEm75+ldgPcCv2LLztO62hGbmZk1QD3vWQwF5uT7Fn2A2yLiB5LuA26TNAP4LV3riM3MuoGbdluZugWLiHgYeGeV9OeBCVuv0fGO2MzMrDH8BLeZmZVysDAzs1LuSNC24mc7zKw1X1mYmVkpBwszMyvlaigz6xFurrtt8ZWFmZmVcrAwM7NSDhZmZlbKwcLMzEo5WJiZWSkHC7MqNr68mqOOOopRo0YxevRorrjiCgDOP/98hg0bBnCgpCWSjq2sI+lcScslPS7p6EL6IZIeyfOuzL0nk3tYvjWnL5Q0srFHaVY7Bwuzavr05dJLL+Wxxx5jwYIFfO1rX2PZsmUAnH322QDLImJMRNwBnR5DfgbwYkTsB1wGXNKYgzPrOAcLsyr69R/I2LFjARgwYACjRo3imWeeaW+VzowhXxyP/rvAhMpVh1mzcbAwK7FixQoefPBBDj30UACuuuoqSNVQ10naIy82DHi6sFplrPhhtD2G/BvrRMRGYC2wZ+v9S5opabGkxatXr+624zLrCAcLs3asX7+eyZMnc/nll7Prrrsya9YsnnzySUiDdLUAl+ZFOzOGfE3jy3tseWsGDhZmbdiwYQOTJ0/m5JNP5oQTTgBgyJAh9O1buRXBt4DxebozY8i/sY6kfsBuwAvdfyRmXedgYVZFRDBjxgxGjRrFOeec80Z6S0tLcbEPAkvzdGfGkC+OR38icE++r2HWdNyRoFkVrz2zjBtvupGDDz6YMWPGAHDRRRdxyy23sGTJEoADgaOAj0Gnx5C/FrhR0nLSFcXU+h+ZWec4WJhVsfPw0VQ7yT/22PRYhaRlEXFccV5Hx5CPiFeBk7opy2Z15WooMzMr5WBhZmal6hYsJO0t6SeSHpP0qKSzcvr5kp7JXSV0qbsEMzNrjHres9gIfCoiHpA0ALhf0l153mUR8eXiwq26S3gzcLekt+abhJXuEhYAd5C6S7gTMzNriLpdWURES0Q8kKfXAY+x+cnVajrTXYKZmTVAQ+5Z5N403wkszElnSnq4G7pLaL0fd4tgZlYHdW86K6k/8B/AJyPiZUlXA18idWvwJVJ3CafTue4StkyMuAa4BmDcuHF+uMlsOzRy9g/bnb/i4r9uUE56l7peWUjagRQoboqI7wFExKqI2BQRr9P17hLMzKwB6tkaSqQnVB+LiK8U0ocWFutqdwlmZtYA9ayGejdwCvCIpCU57XPANEljSFVJK+hadwlmZtYAdQsWEfFzqt9vuKOddTrUXYKZmTWGn+A2M7NSDhZmZlbKvc6amdWgvSa79Wqu29l91qN5sa8szMyslIOFmZmVcrAwM7NSDhZmZlbKwcLMzEo5WJiZWSkHCzMzK9XmcxaSvkobXYEDRMQn6pIjMzNrOu1dWSwG7gd2BsYCT+TXGGBT26uZmdn2ps1gERFzImIOqavwoyLiqxHxVWACKWCYbbc2vryao446ilGjRjF69GiuuOIKAF544QUmTpwIcJCkuwojPSLpXEnLJT0u6ehC+iGSHsnzrsxd7ZO74781py/MI0qaNaVauvt4MzAAeCG/75/TzLZfffpy6aWXMnbsWNatW8chhxzCxIkTuf7665kwYQJ33333UmA+MBv4rKQDganAaNL3425Jb83d7F8NzAQWkHpdnkTqZn8G8GJE7CdpKnAJ8KHOZtkjyDWnnugmpB5qucF9MfCgpOslXQ88AFxU11yZ9bB+/QcyduxYAAYMGMCoUaN45plnmDt3LtOnT68sNgf4QJ4+HvhORLwWEb8BlgPj82Bfu0bEfRERwA2t1pmTp78LTKhcdZg1m3avLCT1AR4HDs0vgNkR8bt6Z8ysWaxYsYIHH3yQQw89lFWrVjF0aBrsMSJaJA3Oiw0jXTlUrMxpG/J06/TKOk/nbW2UtBbYE1hTt4Mx66R2g0VEvC7p0og4HA9lar3Q+vXrmTx5Mpdffjm77rpre4tWuyKIdtLbW2fLDUszSdVYjBgxov0Mm9VJLdVQP5Y02ZfH1tts2LCByZMnc/LJJ3PCCScAMGTIEFpaWoA3xpN/Li++Eti7sPpw4NmcPrxK+hbrSOoH7Mbme4NviIhrImJcRIwbNGhQNx2dWcfUEizOAf4deE3Sy5LWSXq5zvky61ERwYwZMxg1ahTnnHPOG+nHHXccc+ZUbjMwnc1X3LcDU3MLp31JrQgXRUQLsE7SYfmE69RW61RugJwI3JPva5g1ndLWUBExoBEZMWsmrz2zjBtvupGDDz6YMWPGAHDRRRcxe/ZspkyZAmlM+LXASQAR8aik24BlwEbgjNwSCmAWcD2wC6kV1J05/VrgRknLSVcUUxtwaGadUtNIebkt+f6kB/QAiIh765Ups5628/DRtHWSP3/+fCQtjYgJxfSIuBC4sPXyEbGYFFxap79KDjZmza60GkrSR4F7gR8BF+S/59ew3t6SfiLpMUmPSjorpw/MDzM90dWHmszMrDFquWdxFvAu4KmIOAp4J7C6hvU2Ap+KiFHAYcAZ+cGl2cD8iNifzQ810eqhpknA1yX1zduqPNS0f35Nqu3wzMysO9QSLF7Nl8tI2ikifgW8rWyliGiJiAfy9DrgMVK78uKDSF19qMnMzBqglnsWKyXtDvwncJekF9nc9K8muc+bdwILgSG5hUh3PNTUej9uj25mVge1tIb6YJ48X9JPSG3B59W6A0n9gf8APhkRL7dzu6EzDzW1zus1wDUA48aNcxNEszpzf1S9R2mwkPRF4L+BX0TEzzqycUk7kALFTRHxvZy8StLQfFXR1YeazMysAWq5Z7ECmAYslrRI0qWSji9bKbdYuhZ4LCK+UphVfBCpqw81mZlZA9RSDXUdcJ2kPwWmAP9Aui9Q9rDeu4FTgEckLclpnyP1YnubpBnAb+naQ01mZtYAtVRD/StwILCKVB11Iqmb8nZFxM+pfr8B0gBK1dbp0ENNZmbWGLVUQ+0J9AVeInVJsCYiNtYzU2Zm1lxqbg0laRRwNPATSX0jYnj7a5qZ2failmqo9wN/ARwB7AHcQ6qOMjOzXqKWh/KOIfUNdUVEuMmqmVkvVHrPIiLOID1ZfSCApF0kudtyM7NepJZeZ/+ONJj8N3PScFLXH2Zm1kvU0hrqDNIzEy8DRMQTwOB21zAzs+1KLcHitYj4Y+VNHivY/S6ZmfUitQSLn0n6HLCLpImk8bj/q77ZMjOzZlJLsPgsabCjR4CPAXcAn69npszMrLm023RWUh/g4Yg4CPhWY7JkZmbNpt0ri4h4HXhIkkcSMjPrxWp5KG8o8KikRcArlcSIOK5uuTIzs6ZSS7C4oO65MDOzplZLR4IdGh3PzMy2P7W0hjLrlU4//XQGDx7MQQdtHkrl/PPPZ9iwYQAHSloi6djKPEnnSlou6XFJRxfSD5H0SJ53ZR7xkTwq5K05faGkkY07OrOOcbAwa8Npp53GvHnztko/++yzAZZFxJiIuANA0oHAVGA0MAn4uqS+eZWrSaNL7p9fk3L6DODFiNgPuAy4pH5HY9Y1DhZmbTjiiCMYOHBgrYsfD3wnIl6LiN8Ay4HxkoYCu0bEfRERwA3ABwrrzMnT3wUmVK46zJpNm/csJD1C9W49BEREvL1uuTJrYldddRWkaqjrgE9FxIvAMFLvzBUrc9qGPN06nfz3aYCI2ChpLWlkyjXF/UmaSboyYcQIt2K3ntHeDe73NywXZtuIWbNm8YUvfIF+/fotA1qAS4HTqT7efLSTTsm8zQkR1wDXAIwbN879slmPaDNYRMRTjcyI2bZgyJAhxbffAn6Qp1cCexfmDQeezenDq6QX11mZO+jcjTTOvVnTqWU8i8Mk/VLSekl/lLRJ0suNyJxZs2lpaSm+/SCwNE/fDkzNLZz2Jd3IXhQRLcC6/D0ScCowt7DO9Dx9InBPvq9h1nRqucF9FTANeALYBfgo8NWylSRdJ+k5SUsLaedLeiY3OexSs0Ozeps2bRqHH344jz/+OMOHD+faa6/lM5/5DAcffDCkkSOPAs4GiIhHgduAZcA84IyI2JQ3NQv4V9JN7yeBO3P6tcCekpYD5wCzG3RoZh1WyxPcRMRySX1z4f83Sb+oYbXrSYHmhlbpl0XEl4sJrZodvhm4W9Jb8/4qzQ4XkHq8ncTmL5tZ3dxyyy1bpc2YMQMASctad3kTERcCF7ZeJyIWAwdVSX8VOKmbsmtWV7VcWfxe0o7AEkn/Iuls4E1lK0XEvdRe/9qZZodmZtYgtQSLU/JyZ5I6EtwbOKEL+zxT0sO5mmqPnPZGE8Ks0rxwGG03O9yKpJmSFktavHr16i5k0czMimoJFh+IiFcj4uWIuCAizqHzzWqvBv4MGMPmZofQuWaHW8+IuCYixkXEuEGDBnUyi2Zm1lotwWJ6lbTTOrOziFgVEZvyOBnfAsbnWZ1pdmhmZg3S3hPc04APA/tKur0wa1fg+c7sTNLQ3JQQtm52eLOkr5BucFeaHW6StE7SYcBCUrPD0pZYZmbWvdprDfULUlXRXmyuLgJYBzxctmFJtwBHAntJWgmcBxwpaQypKmkFaUxvIuJRSZVmhxvZutnh9aRmu3fillBmZg1X9gT3U8DhkoYA78qzHouIjWUbjohpVZKvbWf5DjU7NDOzxqnlCe6TgEWk9uBTgIWSTqx3xszMrHnU8lDe54F3RcRzAJIGAXeTulQ2M7NeoJbWUH0qgSJ7vsb1zMxsO1HLlcU8ST8CKn0ffAjfZDYz61VKg0VEfFrSCcB7SA/JXRMR3697zszMrGmUBgtJl0TEZ4HvVUkzM7NeoJZ7DxOrpB3T3RkxM7Pm1d4T3LOAvwfeIqn4EN4A4H/qnTEzM2se7VVD3Uy6kf3PbDkoy7qI8NCPZma9SHtPcK8F1pJGyTMzs17Mz0uYmVkpBwszMyvlYGFmZqUcLMzMrJSDhZmZlXKwMDOzUg4WZmZWysHCrA2nn346gwcP5qCDNg/U+MILLzBx4kSAgyTdJWmPyjxJ50paLulxSUcX0g+R9Eied6Uk5fSdJN2a0xdKGtm4ozPrGAcLszacdtppzJs3b4u0iy++mAkTJgAsBeaTezeQdCAwFRgNTAK+LqlvXu1qYCawf35NyukzgBcjYj/gMuCSeh6PWVc4WJi14YgjjmDgwIFbpM2dO5fp06dX3s4BPpCnjwe+ExGvRcRvgOXAeElDgV0j4r6ICOCGVuvMydPfBSZUrjrMmo2DhVkHrFq1iqFDhwIQES3A4DxrGPB0YdGVOW1Ynm6dvsU6EbGR1L3Onq33KWmmpMWSFq9evbr7DsasA+oWLCRdJ+k5SUsLaQNzPe8TXa3vNWsy1cpltJPe3jpbJkRcExHjImLcoEGDupBFs86r55XF9Wyum62YDcyPiP3pen2vWcMNGTKElpYWAHIVU2V8+pXA3oVFhwPP5vThVdK3WEdSP2A3wD06W1OqW7CIiHvZuuAX62i7Wt9r1nDHHXccc+ZUijDTgbl5+nZgam7htC/pxGZRrqpaJ+mwfFV8aqt1KjdATgTuyeXcrOmUDqvazYbkLw8R0SKpWN+7oLBcpV53A23X95rV1bRp0/jpT3/KmjVrGD58OBdccAGzZ89mypQpAAeR7jGcBBARj0q6DVgGbATOiIhNeVOzSFfau5DGiLkzp18L3ChpOenEamqDDs2swxodLNrSmfrerTcizSRVWTFixIjuyZn1WrfcckvV9Pnz5yNpaURMKKZHxIXAha2Xj4jFpODSOv1VcrAxa3aNbg21KlctdUd971Z8I9DMrD4aHSyKdbRdre81M7MGqVs1lKRbgCOBvSStBM4DLgZukzQD+C1dq+81M7MGqVuwiIi2xu6eUC2xo/W9ZmbWOH6C28zMSjlYmJlZKQcLMzMr5WBhZmalHCzMzKyUg4WZmZVysDAzs1IOFmZmVsrBwszMSjlYmJlZKQcLMzMr5WBhZmalHCzMzKyUg4WZmZVysDAzs1IOFmZmVsrBwszMSjlYmJlZKQcLMzMr5WBhZmalHCzMOudgSY9IWiJpMYCkgZLukvRE/rtHZWFJ50paLulxSUcX0g/J21ku6UpJ6omDMSvjYGHWeUdFxJiIGJffzwbmR8T+wPz8HkkHAlOB0cAk4OuS+uZ1rgZmAvvn16QG5t+sZj0SLCSt6I6zMrMmczwwJ0/PAT5QSP9ORLwWEb8BlgPjJQ0Fdo2I+yIigBsK65g1lZ68suiOszKznvRjSfdLmpnfD4mIFoD8d3BOHwY8XVhvZU4blqdbp29B0kxJiyUtXr16dXcfg1lNmqkaqkNnZY3PntkWfhURY4FjgDMkHdHOstXuQ0Q76VsmRFwTEeMiYtygQYM6l1uzLuqpYBF0/axsKz4DswbaABARzwHfJ53ArMpVS+S/z+VlVwJ7F9YdDjyb04dXSTdrOj0VLN7dDWdlWyf6DMwa4JVXXoH83ZH0JuB9wFLgdmB6Xmw6MDdP3w5MlbSTpH1JN7IX5ZOidZIOy62gTi2sY9ZU+vXETiPi2fz3OUlbnJVFREuNZ2VmPWLVqlUAB0h6iPQdujki5kn6JXCbpBnAb4GTACLiUUm3AcuAjcAZEbEpb24WcD2wC3Bnfpk1nYYHi3wm1ici1hXOyr7I5rOyi9n6rOxmSV8B3kw+K2t0vs0q3vKWtwAsKzTOACAingcmVFsnIi4ELqySvhg4qA7ZNOtWPXFlMQT4fn72qKtnZWZm1gANDxYR8WvgHVXSO3xWZmZmjdFMTWfNzKxJOViYmVkpBwszMyvlYGFmZqUcLMzMrJSDhZmZlXKwMDOzUg4WZmZWysHCzMxKOViYmVkpBwszMyvlYGFmZqUcLMzMrJSDhZmZlXKwMDOzUg4WZmZWysHCzMxKOViYmVkpBwszMyvlYGFmZqUcLMzMrJSDhZmZldpmgoWkSZIel7Rc0uyezo9Zd3HZtm3BNhEsJPUFvgYcAxwITJN0YM/myqzrXLZtW7FNBAtgPLA8In4dEX8EvgMc38N5MusOLtu2TVBE9HQeSkk6EZgUER/N708BDo2IM1stNxOYmd++DXi8hs3vBazpxux2h2bLk/OztX0iYlBXN1JL2e5kuYbm+JyKmi0/0Hx56un8tFmu+zU6J52kKmlbRbmIuAa4pkMblhZHxLjOZqwemi1Pzk9dlZbtzpRraL7PqdnyA82Xp2bLT9G2Ug21Eti78H448GwP5cWsO7ls2zZhWwkWvwT2l7SvpB2BqcDtPZwns+7gsm3bhG2iGioiNko6E/gR0Be4LiIe7abNd/jyvgGaLU/OT530srLdbPmB5stTs+XnDdvEDW4zM+tZ20o1lJmZ9SAHCzMzK9VrgkVZlwpKrszzH5Y0to552VvSTyQ9JulRSWdVWeZISWslLcmv/1uv/BT2uULSI3l/i6vMb+Rn9LbCsS+R9LKkT7ZapuGfUTNy2a4pXy7bXRUR2/2LdOPwSeAtwI7AQ8CBrZY5FriT1O79MGBhHfMzFBibpwcA/1slP0cCP2jw57QC2Kud+Q37jKr8/35HemCoRz+jZnu5bNecL5ftLr56y5VFLV0qHA/cEMkCYHdJQ+uRmYhoiYgH8vQ64DFgWD321c0a9hm1MgF4MiKeasC+tjUu293DZbtEbwkWw4CnC+9XsnUBrmWZbidpJPBOYGGV2YdLekjSnZJG1zsvpCeHfyzp/tzFRGs98hmRnj24pY15jf6Mmo3Ldm1ctrtom3jOohvU0l1ITV2KdCdJ/YH/AD4ZES+3mv0A6dJ0vaRjgf8E9q9nfoB3R8SzkgYDd0n6VUTcW8xylXXq/RntCBwHnFtldk98Rs3GZbs2Lttd1FuuLGrpUqGh3S5I2oH0ZbopIr7Xen5EvBwR6/P0HcAOkvaqV37yfp7Nf58Dvk+q4ijqia4pjgEeiIhVrWf0xGfUhFy2a+Cy3XW9JVjU0qXC7cCpuVXEYcDaiGipR2YkCbgWeCwivtLGMn+al0PSeNL/6vl65Cfv402SBlSmgfcBS1st1rDPqGAabVymN/ozalIu2+V5ctnuBr2iGira6FJB0sfz/G8Ad5BaRCwHfg98pI5ZejdwCvCIpCU57XPAiEJ+TgRmSdoI/AGYGrmZRJ0MAb6fy2c/4OaImNeDnxGS/gSYCHyskFbMT6M/o6bjsl0Tl+1u4O4+zMysVG+phjIzsy5wsDAzs1IOFmZmVsrBwszMSjlYmJlZKQcLM9tmSPqipPd2w3bWd3K9j0k6TdIYSd/oaj62JW46a2a9jqT1EdG/E+t9GzgPeD+wJiJu6vbMNSlfWZhZj5H0t5IW5TEbvimpb05fL+lSSQ9Imi9pUE6/XtKJefpiScuUxp/4ck7bJy//cP47IqfvK+k+Sb+U9KVWefh0Tn9Y0gVt5PPs/JDhB0ldmVwA/GNvurpwsDCzHiFpFPAhUid/Y4BNwMl59ptI/SaNBX5GOpsvrjuQ9MM9OiLeDvxTnnUVqavxtwM3AVfm9CuAqyPiXaTxIyrbeR+pg77xwBjgEElHtM5rRFxGeuJ6fs7rExFxYER8vCufwbbEwcLMesoE4BDgl/msfQJpECeA14Fb8/S3gfe0Wvdl4FXgXyWdQOqiA+Bw4OY8fWNhvXezuR+mGwvbeV9+PUjq6fUA2u7ddSzwUO5n6sWajnA70iv6hjKzpiRgTkRU66K7tS1uruY+scaTAsxU4Ezgr0rWq3aDVsA/R8Q328xk6tb8x8BgUoCaBgzIAW5yRDxZQ/63eb6yMLOeMh84Mf8YI2mgpH3yvD6kzvQAPgz8vLii0ngZu+Xuuz9JqkIC+AUpeECq0qqs9z+t0it+BJyet4ekYZX8VETEc7nq6QFSddW3gY9ExJjeEijAVxZm1kMiYpmkz5NGsOsDbADOAJ4CXgFGS7ofWEu6t1E0AJgraWfS1cHZOf0TwHWSPg2sZnPvsWcBN0s6i3SDupKHH+d7J/flXmnXA38LPFfcWb7xvmdErJH050DV7te3Z246a2ZNp7NNW61+XA1lZmalfGVhZmalfGVhZmalHCzMzKyUg4WZmZVysDAzs1IOFmZmVur/Aznnzzy+NWzjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing RL agent which randomly chooses actions\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import gym\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2020-05', seed=1)\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_1 = []\n",
    "off_line_rewards_lst_1 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    ob = env.reset()\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "\n",
    "    while not done:\n",
    "        # random action as policy\n",
    "        action = env.action_space.sample()\n",
    "        # print(\"step: \", env.count)\n",
    "        # print(\"charging costs: \", env.bats_charge_costs)\n",
    "        # print(\"discharging costs: \", env.bats_discharge_costs)\n",
    "        # print(\"env load: \", env.load_demand)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    # print(\"episode {} mean reward: {}\".format(i, np.mean(rewards)))\n",
    "    rewards_lst_1.append(np.sum(rewards))\n",
    "    ob = env.reset()\n",
    "    off_line_rewards_lst_1.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(list(range(episodes)), rewards_lst_1, width=0.5)\n",
    "plt.title(\"Random Actions\")\n",
    "\n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "# plot episode # versus total offline episode reward\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(list(range(episodes)), off_line_rewards_lst_1, width=0.5)\n",
    "plt.title(\"Offline Optimal\")\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StopTrainingOnNoModelImprovement' from 'stable_baselines3.common.callbacks' (/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-19-141-214.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstable_baselines3\u001b[39;00m \u001b[39mimport\u001b[39;00m PPO\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-19-141-214.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstable_baselines3\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EvalCallback, StopTrainingOnNoModelImprovement\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-19-141-214.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=3'>4</a>\u001b[0m env \u001b[39m=\u001b[39m BatteryStorageInGridEnv(date\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2020-05\u001b[39m\u001b[39m'\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-19-141-214.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=5'>6</a>\u001b[0m stop_train_callback \u001b[39m=\u001b[39m StopTrainingOnNoModelImprovement(max_no_improvement_evals\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, min_evals\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'StopTrainingOnNoModelImprovement' from 'stable_baselines3.common.callbacks' (/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py)"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2020-05', seed=1)\n",
    "\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "model.learn(callback=eval_callback)\n",
    "model.save(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_4 = []\n",
    "off_line_rewards_lst_4 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_4.append(np.sum(rewards))\n",
    "    ob = env.reset()\n",
    "    off_line_rewards_lst_4.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.bar(list(range(episodes)), rewards_lst_4)\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #') \n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "[nan nan]\n",
      "[nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/policies.py:376: RuntimeWarning: invalid value encountered in multiply\n",
      "  return low + (0.5 * (scaled_action + 1.0) * (high - low))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parameter value must be nonnegative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=11'>12</a>\u001b[0m \u001b[39m# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=12'>13</a>\u001b[0m model \u001b[39m=\u001b[39m DDPG(\u001b[39m\"\u001b[39m\u001b[39mMultiInputPolicy\u001b[39m\u001b[39m\"\u001b[39m, env, action_noise\u001b[39m=\u001b[39maction_noise, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m200000\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mddpg_single_agent_battery_env\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=16'>17</a>\u001b[0m \u001b[39m# del model # remove to demonstrate saving and loading\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py:130\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    118\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    119\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    128\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(DDPG, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    131\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    132\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    133\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    134\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    135\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    136\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    137\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    138\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    139\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    140\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/td3/td3.py:205\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    194\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    203\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(TD3, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    206\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    207\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    208\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    209\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    210\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    211\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    212\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    213\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    214\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    215\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:354\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    351\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    353\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 354\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    355\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    356\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    357\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    358\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    359\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    360\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    361\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    362\u001b[0m     )\n\u001b[1;32m    364\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:587\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    584\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[1;32m    586\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 587\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m    589\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    590\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx][\u001b[39m\"\u001b[39m\u001b[39mterminal_observation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m obs\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/monitor.py:90\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/sustaingym/sustaingym/tests/../envs/MO_single_agent_battery_storage_env.py:544\u001b[0m, in \u001b[0;36mBatteryStorageInGridEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_max_discharge \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mminimum(\n\u001b[1;32m    535\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_max_discharge_range[:, \u001b[39m1\u001b[39m],\n\u001b[1;32m    536\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbattery_charge \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDISCHARGE_EFFICIENCY \u001b[39m/\u001b[39m time_step)\n\u001b[1;32m    538\u001b[0m \u001b[39m# print(\"agent max discharge: \", self.bats_max_discharge[-1])\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m# print(\"agent max charge: \", self.bats_max_charge[-1])\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39m# print(\"agent curr charge: \", self.battery_charge[-1])\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39m# print(\"agent charge cost: \", self.bats_charge_costs[-1])\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[39m# print(\"agent discharge cost: \", self.bats_discharge_costs[-1])\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m _, x_bats, price \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarket_op\u001b[39m.\u001b[39;49mget_dispatch()\n\u001b[1;32m    545\u001b[0m x_agent \u001b[39m=\u001b[39m x_bats[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    547\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([x_agent], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/sustaingym/sustaingym/tests/../envs/MO_single_agent_battery_storage_env.py:87\u001b[0m, in \u001b[0;36mMarketOperator.get_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_max_charge\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mbats_max_charge\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_max_discharge\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mbats_max_discharge\n\u001b[0;32m---> 87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_charge_costs\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mbats_charge_costs\n\u001b[1;32m     88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_discharge_costs\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mbats_discharge_costs\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mload_demand\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/cvxpy/expressions/constants/parameter.py:86\u001b[0m, in \u001b[0;36mParameter.value\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m@value\u001b[39m\u001b[39m.\u001b[39msetter\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalue\u001b[39m(\u001b[39mself\u001b[39m, val):\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_value(val)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/cvxpy/expressions/leaf.py:438\u001b[0m, in \u001b[0;36mLeaf._validate_value\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m             attr_str \u001b[39m=\u001b[39m ([k \u001b[39mfor\u001b[39;00m (k, v) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattributes\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v] \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mreal\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 438\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    439\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m value must be \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, attr_str)\n\u001b[1;32m    440\u001b[0m         )\n\u001b[1;32m    441\u001b[0m \u001b[39mreturn\u001b[39;00m val\n",
      "\u001b[0;31mValueError\u001b[0m: Parameter value must be nonnegative."
     ]
    }
   ],
   "source": [
    "from stable_baselines3.ddpg.policies import MultiInputPolicy\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3 import DDPG\n",
    "import numpy as np\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\n",
    "model = DDPG(\"MultiInputPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=200000)\n",
    "model.save(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "episodes = 100\n",
    "\n",
    "rewards_lst_2 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_2.append(np.sum(rewards))\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.bar(list(range(episodes)), rewards_lst_2)\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #') \n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sustaingym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c910351b0c3a4aade2cf03b555240fe9951314ae7b50b4f56bc279231ceafe8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
