{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing environment with stable_baselines3 library\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from envs.MO_single_agent_battery_storage_env import BatteryStorageInGridEnv\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:09<00:00,  1.44it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing RL agent which randomly chooses actions\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import gym\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "episodes = 100\n",
    "\n",
    "rewards_lst_1 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    ob = env.reset()\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "\n",
    "    while not done:\n",
    "        # random action as policy\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    # print(\"episode {} mean reward: {}\".format(i, np.mean(rewards)))\n",
    "    rewards_lst_1.append(np.sum(rewards))\n",
    "\n",
    "# print(rewards_lst_1)\n",
    "# plot episode # versus total episode reward\n",
    "plt.bar(list(range(episodes)), rewards_lst_1, width=0.5)\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #') \n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=6'>7</a>\u001b[0m \u001b[39m# the noise objects for DDPG\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=7'>8</a>\u001b[0m \u001b[39m# n_actions = env.action_space.shape[-1]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=8'>9</a>\u001b[0m \u001b[39m# action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=9'>10</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m DDPG(MultiInputPolicy, env, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m200000\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mddpg_single_agent_battery_env\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=15'>16</a>\u001b[0m \u001b[39m# del model # remove to demonstrate saving and loading\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py:130\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    118\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    119\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    128\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(DDPG, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    131\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    132\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    133\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    134\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    135\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    136\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    137\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    138\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    139\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    140\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/td3/td3.py:205\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    194\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    203\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(TD3, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    206\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    207\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    208\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    209\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    210\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    211\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    212\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    213\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    214\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    215\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:354\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    351\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    353\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 354\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    355\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    356\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    357\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    358\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    359\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    360\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    361\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    362\u001b[0m     )\n\u001b[1;32m    364\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:587\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    584\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[1;32m    586\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 587\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m    589\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    590\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx][\u001b[39m\"\u001b[39m\u001b[39mterminal_observation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m obs\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/monitor.py:90\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/sustaingym/sustaingym/tests/../envs/MO_single_agent_battery_storage_env.py:310\u001b[0m, in \u001b[0;36mBatteryStorageInGridEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit\n\u001b[1;32m    309\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_type \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 310\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mcontains(action)\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    314\u001b[0m \u001b[39m# ensure selling cost (a) for charge is at least as large as buying cost (b)\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3.ddpg.policies import MultiInputPolicy\n",
    "from stable_baselines3.common.noise import OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3 import DDPG\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "# the noise objects for DDPG\n",
    "# n_actions = env.action_space.shape[-1]\n",
    "# action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\n",
    "model = DDPG(MultiInputPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=200000)\n",
    "model.save(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "episodes = 100\n",
    "\n",
    "rewards_lst_2 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_2.append(np.sum(rewards))\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.bar(list(range(episodes)), rewards_lst_2)\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #') \n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:22<00:00,  1.22it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVVElEQVR4nO3df7TcdX3n8ecLsGgBW5DAxgQM7aIVetpgI9XSdVWqqPUUtGhDVxu7duPuwhGt6wrqHqVdTtk9omvXrTUqNa38KKtYstZVkHJkrS4QYopAZEkLSCSSoK1Ae0CD7/3j+71fxuTem8nNnZl7Z56Pc+bcmc/Md+b9yb2Z13w/38/3M6kqJEkCOGDUBUiSFg5DQZLUMRQkSR1DQZLUMRQkSZ2DRl3A/jjyyCNrxYoVoy5DkhaVW2655cGqWjLdfYs6FFasWMHGjRtHXYYkLSpJ7p3pPoePJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1BlYKCQ5Jsn1SbYkuT3JuW37e5N8K8nm9vKKnm3OT7I1yZ1JThtUbZKk6Q3yPIVdwNuqalOSw4Bbklzb3veBqnpf74OTnACsBk4Eng58Mckzq+rxAdYoSeoxsD2FqtpeVZva6w8DW4Bls2xyOnBFVT1WVXcDW4GTB1WfJGlPQzmmkGQFcBJwY9t0TpJbk1yS5PC2bRlwX89m25gmRJKsTbIxycadO3cOsmxJ+2jFeX/JivP+ctRlaD8MPBSSHAp8GnhLVT0EfBj4aWAlsB24eOqh02y+x9fCVdW6qlpVVauWLJl26Q5JE8hAmh8DDYUkT6IJhEur6iqAqnqgqh6vqh8CH+WJIaJtwDE9my8H7h9kfZKkHzXI2UcBPg5sqar397Qv7XnYq4Db2usbgNVJDk5yHHA8cNOg6pMk7WmQs49OAV4PfD3J5rbtncBZSVbSDA3dA7wJoKpuT3IlcAfNzKWznXkkScM1sFCoqi8z/XGCz82yzYXAhYOqSZI0O89oliR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkDR2XPJi7gwFSVLHUJAkdQwFSVLHUJAkdQwFSTPygO3kMRQkSR1DQfvNT5PS+DAUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0ED45nO0uJjKEiSOoaCJKljKEiSOoaCJKljKEiSOgeNugA9oXemzj0X/eoIK9E4mfq78m9K/TAUpCEw8LVYOHwkSeoMLBSSHJPk+iRbktye5Ny2/Ygk1ya5q/15eM825yfZmuTOJKcNqjZJ0vQGOXy0C3hbVW1KchhwS5JrgTcA11XVRUnOA84D3pHkBGA1cCLwdOCLSZ5ZVY8PsEYtUA63SKMxsD2FqtpeVZva6w8DW4BlwOnA+vZh64Ez2uunA1dU1WNVdTewFTh5UPVJkvY0lGMKSVYAJwE3AkdX1XZoggM4qn3YMuC+ns22tW0aAtcpkgRDCIUkhwKfBt5SVQ/N9tBp2mqa51ubZGOSjTt37pyvMiVJDDgUkjyJJhAuraqr2uYHkixt718K7GjbtwHH9Gy+HLh/9+esqnVVtaqqVi1ZsmRwxUvSBBrk7KMAHwe2VNX7e+7aAKxpr68Bru5pX53k4CTHAccDNw2qPknSngY5++gU4PXA15NsbtveCVwEXJnkjcA3gdcAVNXtSa4E7qCZuXS2M4/UL2crSfNjYKFQVV9m+uMEAKfOsM2FwIWDqkmSNDvPaJ4jZ+tIGkeufTTmHFbRfHFhvX2zWP/vGQqS9oth8YRxGD1w+EiS1DEU9sJjB5ImicNH0oA4rLJvFusY/LhxT0GS1HFPYUz4KUvSfHBPQZLUMRQkSR2Hj+bBYjqguJhq1eK2UIY0+/mb9//FE9xTkCR1DAVJUsdQkKR91HtS67id4GooSJI6hoIkqWMoSJI6TkmVNFSLaarqJHJPQWNv3A4ESoNkKEiSOoaCJKljKEiSOoaCJKkz4+yjJP8dqJnur6o3D6QiSdLIzLansBG4BXgy8BzgrvayEnh84JVp4JyVI2l3M+4pVNV6gCRvAF5UVT9ob/8xcM1QqpOkIZv08xf6OXnt6cBhwHfb24e2bZKkebJQTurrJxQuAr6W5Pr29r8E3juwisbIpH/ikLT4zBoKSQ4A7gR+sb0AnFdV3x50YZI0LhbKXkA/Zg2Fqvphkour6vnA1UOqSZI0Iv0MH12T5NeBq6pqximqkqTBGsYeRz+h8LvAIcCuJI8CAaqqnjqQiqQJtZiGGDS+9hoKVXXYMAqRNHk8T2bh6WuZiySHJzk5yQumLn1sc0mSHUlu62l7b5JvJdncXl7Rc9/5SbYmuTPJaXPrjiRpf+x1TyHJ7wDnAsuBzcDzgK8CL97Lpp8APgT86W7tH6iq9+32GicAq4ETac6B+GKSZ1aVZ05r4jmspGHqZ0/hXOC5wL1V9SLgJGDn3jaqqht44oS3vTkduKKqHququ4GtwMl9bitJmif9hMKjVfUoQJKDq+obwLP24zXPSXJrO7x0eNu2DLiv5zHb2rY9JFmbZGOSjTt37jWbpKFyPSktdv2EwrYkPwn8BXBtkquB++f4eh8GfppmUb3twMVte6Z57LTTX6tqXVWtqqpVS5YsmWMZ0uI3FUCGkOZTP7OPXtVefW+71MVPAJ+fy4tV1QNT15N8FPhse3MbcEzPQ5cz9+CRJM1RPweafw/4P8BXqupL+/NiSZZW1fb25quAqZlJG4DLkryf5kDz8cBN+/Na0kLlgePJttB///2cvHYPcBbwh0kepgmIG6pq1mUvklwOvBA4Msk24D3AC5OspBkaugd4E0BV3Z7kSuAOYBdwtjOPJGn4+hk+ugS4JMk/A14L/AdgLc1y2rNtd9Y0zR+f5fEXAhfurR5J0uD0M3z0MeAE4AGavYQzgU0DrkuSNAL9DB89DTgQ+Aea8w4erKpdgyxKk2Ohj69Kk6bv2UdJng2cBlyf5MCqWj7o4qSFxC9N0iToZ/jolcC/AF4AHA78Fc0wkrQH3zilxa2f4aOXAzcAH6wqzx2QpDHWz/DR2UmeQXOw+f4kTwEOqqqHB16dxsYg9iA8k1eaf3td5iLJvwE+BXykbVpOs+SFJGnM9DN8dDbNiqU3AlTVXUmOGmhVUo9JnKHkXpBGpZ9QeKyqvp80a9YlOYgZFqvTcPnGIQ3WoCdOLMT/w/2skvqlJO8EnpLkJcD/BP7XYMuSJI1CP6HwDpov1fk6zVpFnwPePciiFjOXMpa0mM06fJTkAODWqvpZ4KPDKUnaP8M+BrFYz81YrHVrsGbdU6iqHwJ/k+TYIdUjSRqhfg40LwVuT3IT8I9TjVX1awOraoI41LRv/PdanObr9zaJM9GGrZ9QuGDgVUiSFoR+zmjer29bkzR4foLWfOlnT0GLjEMsmkk/B5c9AD3Z+pmSKk0UpxVrkhkKkqTOjMNHSb7O9MtZBKiq+rmBVSVJGonZjim8cmhVSFIPD5yPzoyhUFX3DrMQLRweaBwej11ooenn+xSel+TmJI8k+X6Sx5M8NIziJEnD1c+U1A8Bq2lWR10F/BbwzwdZ1Djy07fmg3sWGrS+zlOoqq1JDqyqx4E/SfKVAdelBcIwkyZLP6HwT0l+DNic5L8C24FDBlvWcCyWNzwPukmTa9h7h/2cp/D69nHn0CyIdwzw6kEWJUkajX5C4YyqerSqHqqqC6rqd3G6qiSNpX5CYc00bW+Y5zokSQvAbGc0nwX8JnBckg09dz0V+M6gC5t0zjJZGBbLcSdpvsx2oPkrNAeVjwQu7ml/GLh1kEUtVL5BSBp3ezuj+V7g+UmOBp7b3rWlqnYNozhpkAx5aU/9nNH8GuAm4DXAa4Ebk5zZx3aXJNmR5LaetiOSXJvkrvbn4T33nZ9ka5I7k5w2t+5IkvZHPwea3w08t6rWVNVvAScD/6mP7T4BvGy3tvOA66rqeOC69jZJTqA5a/rEdps/SnJgXz3Q0Pg9A+NrX3+3/i2Mr35C4YCq2tFz+zv9bFdVNwDf3a35dGB9e309cEZP+xVV9VhV3Q1spQkfaUHyTVHjqp8zmj+f5AvA5e3t3wD+9xxf7+iq2g5QVduTHNW2LwP+b8/jtrVte0iyFlgLcOyxx86xDEnSdPYaClX19iSvBn6Z5gt21lXVZ+a5jkz30jPUsw5YB7Bq1appH6OFbSF+wvags9TYaygk+S9V9Q7gqmna9tUDSZa2ewlLgalhqW00y2dMWQ7cP4fnlyTth36OKbxkmraXz/H1NvDEGdJrgKt72lcnOTjJccDxNDOehsYxYkma/Yzmfwf8e+CnkvSerHYY8Nd7e+IklwMvBI5Msg14D3ARcGWSNwLfpJnmSlXdnuRK4A5gF3B2u0z3SDiUML783Uqzm2346DKaA8p/QDt1tPVwVe0+q2gPVXXWDHedOsPjLwQu3NvzjgPfmCQtVLOd0fw94HvATG/ummAGmzSe+jmmIEmaEIaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOv2skipJGqJRLrnjnoIkqWMoSJI6hoKkieFqyHtnKEiSOh5oXmT8lCNpkAwFSYtS7wckV+udPw4fSZI6hoIkqWMoSJI6hoI0hpx6qbkyFCRJHWcfSVrQ3OMZLvcUJEkdQ0GS+jApx2kMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHU8eU0LxiRM95MWOvcUJEkdQ0GS1BnJ8FGSe4CHgceBXVW1KskRwJ8DK4B7gNdW1d+Poj5JmlSj3FN4UVWtrKpV7e3zgOuq6njguva2JGmIFtLw0enA+vb6euCM0ZUiSZNpVKFQwDVJbkmytm07uqq2A7Q/jxpRbZI0sUY1JfWUqro/yVHAtUm+0e+GbYisBTj22GMHVZ8kTaSR7ClU1f3tzx3AZ4CTgQeSLAVof+6YYdt1VbWqqlYtWbJkWCVL0kQYeigkOSTJYVPXgZcCtwEbgDXtw9YAVw+7NkmadKMYPjoa+EySqde/rKo+n+Rm4MokbwS+CbxmBLVJ0kQbeihU1d8BPz9N+3eAU4ddjyTpCQtpSqokacQMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUWXCgkeVmSO5NsTXLeqOuRpEmyoEIhyYHA/wBeDpwAnJXkhNFWJUmTY0GFAnAysLWq/q6qvg9cAZw+4pokaWKkqkZdQyfJmcDLqup32tuvB36xqs7pecxaYG1781nAnfv5skcCD+7ncyw29nky2OfJMJc+P6Oqlkx3x0H7X8+8yjRtP5JaVbUOWDdvL5hsrKpV8/V8i4F9ngz2eTLMd58X2vDRNuCYntvLgftHVIskTZyFFgo3A8cnOS7JjwGrgQ0jrkmSJsaCGj6qql1JzgG+ABwIXFJVtw/4ZedtKGoRsc+TwT5Phnnt84I60CxJGq2FNnwkSRohQ0GS1JnYUJiE5TSSHJPk+iRbktye5Ny2/Ygk1ya5q/15+KhrnW9JDkzytSSfbW+PdZ+T/GSSTyX5Rvv7fv4E9Pmt7d/1bUkuT/LkcetzkkuS7EhyW0/bjH1Mcn77nnZnktPm8poTGQoTtJzGLuBtVfVs4HnA2W0/zwOuq6rjgeva2+PmXGBLz+1x7/MHgc9X1c8AP0/T97Htc5JlwJuBVVX1szQTU1Yzfn3+BPCy3dqm7WP7f3s1cGK7zR+173X7ZCJDgQlZTqOqtlfVpvb6wzRvFMto+rq+fdh64IyRFDggSZYDvwp8rKd5bPuc5KnAC4CPA1TV96vqHxjjPrcOAp6S5CDgx2nOaRqrPlfVDcB3d2ueqY+nA1dU1WNVdTewlea9bp9MaigsA+7rub2tbRtbSVYAJwE3AkdX1XZoggM4aoSlDcJ/A/4j8MOetnHu808BO4E/aYfMPpbkEMa4z1X1LeB9wDeB7cD3quoaxrjPPWbq47y8r01qKOx1OY1xkuRQ4NPAW6rqoVHXM0hJXgnsqKpbRl3LEB0EPAf4cFWdBPwji3/YZFbtOPrpwHHA04FDkrxutFWN3Ly8r01qKEzMchpJnkQTCJdW1VVt8wNJlrb3LwV2jKq+ATgF+LUk99AMC744yScZ7z5vA7ZV1Y3t7U/RhMQ49/lXgLuramdV/QC4CvglxrvPU2bq47y8r01qKEzEchpJQjPOvKWq3t9z1wZgTXt9DXD1sGsblKo6v6qWV9UKmt/rX1XV6xjvPn8buC/Js9qmU4E7GOM+0wwbPS/Jj7d/56fSHDMb5z5PmamPG4DVSQ5OchxwPHDTPj97VU3kBXgF8P+AvwXeNep6BtTHX6bZfbwV2NxeXgE8jWbWwl3tzyNGXeuA+v9C4LPt9bHuM7AS2Nj+rv8COHwC+nwB8A3gNuDPgIPHrc/A5TTHTH5Asyfwxtn6CLyrfU+7E3j5XF7TZS4kSZ1JHT6SJE3DUJAkdQwFSVLHUJAkdQwFSVLHUJD6kOT3kvzKPDzPI3Pc7k1J3pBkZZI/3t86pJk4JVUaoiSPVNWhc9juk8B7gFcCD1bVpfNenIR7CppQSV6X5KYkm5N8ZGqJ4SSPJLk4yaYk1yVZ0rZ/IsmZ7fWLktyR5NYk72vbntE+/tb257Ft+3FJvprk5iS/v1sNb2/bb01ywQx1vjXJZuBVNMuVXAC8y70FDYqhoImT5NnAbwCnVNVK4HHgX7V3HwJsqqrnAF+i+XTeu+0RNG/QJ1bVzwH/ub3rQ8Cftm2XAn/Ytn+QZqG65wLf7nmel9IsQ3AyzdnIv5DkBbvXWlUfAF5Cs37+SuCuqjqhqv7t/vwbSDMxFDSJTgV+Abi5/RR+Ks3y09Ast/3n7fVP0iwV0ush4FHgY0leDfxT2/584LL2+p/1bHcKzVIFU+1TXtpevgZsAn6GJiSm8xzgb5IcBvx9Xz2U5uigURcgjUCA9VV1fh+P/ZGDblW1K8nJNEGyGjgHePFetpvuwF2AP6iqj8xYZHIUcA3NevmPAmcBh7VB9utV9bd91C/tE/cUNImuA85s33SnvvP2Ge19BwBnttd/E/hy74btd1P8RFV9DngLzdAPwFdoQgKaoaip7f56t/YpXwD+dft8JFk2Vc+UqtrRDhltohlm+iTw21W10kDQoLinoIlTVXckeTdwTZIDaFagPBu4l+YLak5McgvwPZpjD70OA65O8mSaT/tvbdvfDFyS5O0034L22237ucBlSc6lOVA8VcM17bGNrzYrP/MI8Dp2W/+/PQD+tKp6MMkvAb1LoEvzzimpUo+5ThmVxoXDR5KkjnsKkqSOewqSpI6hIEnqGAqSpI6hIEnqGAqSpM7/B5idgEDIRnu0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "# model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "# model.learn(total_timesteps=200000)\n",
    "# model.save(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "episodes = 100\n",
    "\n",
    "rewards_lst_4 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_4.append(np.sum(rewards))\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.bar(list(range(episodes)), rewards_lst_4)\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #') \n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sustaingym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c910351b0c3a4aade2cf03b555240fe9951314ae7b50b4f56bc279231ceafe8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
