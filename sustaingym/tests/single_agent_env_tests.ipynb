{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:272: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing environment with stable_baselines3 library\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from envs.MO_single_agent_battery_storage_env import BatteryStorageInGridEnv\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing RL agent which randomly chooses actions\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import gym\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_1 = []\n",
    "off_line_rewards_lst_1 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    ob = env.reset()\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "\n",
    "    while not done:\n",
    "        # random action as policy\n",
    "        action = env.action_space.sample()\n",
    "        # print(\"step: \", env.count)\n",
    "        # print(\"charging costs: \", env.bats_charge_costs)\n",
    "        # print(\"discharging costs: \", env.bats_discharge_costs)\n",
    "        # print(\"env load: \", env.load_demand)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    # print(\"episode {} mean reward: {}\".format(i, np.mean(rewards)))\n",
    "    rewards_lst_1.append(np.sum(rewards))\n",
    "    off_line_rewards_lst_1.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(list(range(episodes)), rewards_lst_1, width=0.5)\n",
    "plt.title(\"Random Actions\")\n",
    "\n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "# plot episode # versus total offline episode reward\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(list(range(episodes)), off_line_rewards_lst_1, width=0.5)\n",
    "plt.title(\"Offline Optimal\")\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StopTrainingOnNoModelImprovement' from 'stable_baselines3.common.callbacks' (/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000005vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstable_baselines3\u001b[39;00m \u001b[39mimport\u001b[39;00m PPO\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000005vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstable_baselines3\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EvalCallback, StopTrainingOnNoModelImprovement\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000005vscode-remote?line=3'>4</a>\u001b[0m env \u001b[39m=\u001b[39m BatteryStorageInGridEnv()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000005vscode-remote?line=5'>6</a>\u001b[0m stop_train_callback \u001b[39m=\u001b[39m StopTrainingOnNoModelImprovement(max_no_improvement_evals\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, min_evals\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'StopTrainingOnNoModelImprovement' from 'stable_baselines3.common.callbacks' (/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py)"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "model.learn(callback=eval_callback)\n",
    "model.save(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_4 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_4.append(np.sum(rewards))\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.bar(list(range(episodes)), rewards_lst_4)\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #') \n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "[nan nan]\n",
      "[nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/policies.py:376: RuntimeWarning: invalid value encountered in multiply\n",
      "  return low + (0.5 * (scaled_action + 1.0) * (high - low))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parameter value must be nonnegative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=11'>12</a>\u001b[0m \u001b[39m# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=12'>13</a>\u001b[0m model \u001b[39m=\u001b[39m DDPG(\u001b[39m\"\u001b[39m\u001b[39mMultiInputPolicy\u001b[39m\u001b[39m\"\u001b[39m, env, action_noise\u001b[39m=\u001b[39maction_noise, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m200000\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mddpg_single_agent_battery_env\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-22-167-78.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=16'>17</a>\u001b[0m \u001b[39m# del model # remove to demonstrate saving and loading\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py:130\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    118\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    119\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    128\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(DDPG, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    131\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    132\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    133\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    134\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    135\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    136\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    137\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    138\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    139\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    140\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/td3/td3.py:205\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    194\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    203\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(TD3, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    206\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    207\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    208\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    209\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    210\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    211\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    212\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    213\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    214\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    215\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:354\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    351\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    353\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 354\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    355\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    356\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    357\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    358\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    359\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    360\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    361\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    362\u001b[0m     )\n\u001b[1;32m    364\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:587\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    584\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[1;32m    586\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 587\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m    589\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    590\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx][\u001b[39m\"\u001b[39m\u001b[39mterminal_observation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m obs\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/monitor.py:90\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/sustaingym/sustaingym/tests/../envs/MO_single_agent_battery_storage_env.py:544\u001b[0m, in \u001b[0;36mBatteryStorageInGridEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_max_discharge \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mminimum(\n\u001b[1;32m    535\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_max_discharge_range[:, \u001b[39m1\u001b[39m],\n\u001b[1;32m    536\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbattery_charge \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDISCHARGE_EFFICIENCY \u001b[39m/\u001b[39m time_step)\n\u001b[1;32m    538\u001b[0m \u001b[39m# print(\"agent max discharge: \", self.bats_max_discharge[-1])\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m# print(\"agent max charge: \", self.bats_max_charge[-1])\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39m# print(\"agent curr charge: \", self.battery_charge[-1])\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39m# print(\"agent charge cost: \", self.bats_charge_costs[-1])\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[39m# print(\"agent discharge cost: \", self.bats_discharge_costs[-1])\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m _, x_bats, price \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarket_op\u001b[39m.\u001b[39;49mget_dispatch()\n\u001b[1;32m    545\u001b[0m x_agent \u001b[39m=\u001b[39m x_bats[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    547\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([x_agent], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/sustaingym/sustaingym/tests/../envs/MO_single_agent_battery_storage_env.py:87\u001b[0m, in \u001b[0;36mMarketOperator.get_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_max_charge\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mbats_max_charge\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_max_discharge\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mbats_max_discharge\n\u001b[0;32m---> 87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_charge_costs\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mbats_charge_costs\n\u001b[1;32m     88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbats_discharge_costs\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mbats_discharge_costs\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mload_demand\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/cvxpy/expressions/constants/parameter.py:86\u001b[0m, in \u001b[0;36mParameter.value\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m@value\u001b[39m\u001b[39m.\u001b[39msetter\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalue\u001b[39m(\u001b[39mself\u001b[39m, val):\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_value(val)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/cvxpy/expressions/leaf.py:438\u001b[0m, in \u001b[0;36mLeaf._validate_value\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m             attr_str \u001b[39m=\u001b[39m ([k \u001b[39mfor\u001b[39;00m (k, v) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattributes\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v] \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mreal\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 438\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    439\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m value must be \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, attr_str)\n\u001b[1;32m    440\u001b[0m         )\n\u001b[1;32m    441\u001b[0m \u001b[39mreturn\u001b[39;00m val\n",
      "\u001b[0;31mValueError\u001b[0m: Parameter value must be nonnegative."
     ]
    }
   ],
   "source": [
    "from stable_baselines3.ddpg.policies import MultiInputPolicy\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3 import DDPG\n",
    "import numpy as np\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\n",
    "model = DDPG(\"MultiInputPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=200000)\n",
    "model.save(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "episodes = 100\n",
    "\n",
    "rewards_lst_2 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_2.append(np.sum(rewards))\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.bar(list(range(episodes)), rewards_lst_2)\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #') \n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sustaingym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c910351b0c3a4aade2cf03b555240fe9951314ae7b50b4f56bc279231ceafe8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
