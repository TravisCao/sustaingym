{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:272: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing environment with stable_baselines3 library\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from envs.MO_single_agent_battery_storage_env import BatteryStorageInGridEnv\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing RL agent which randomly chooses actions\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import gym\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "episodes = 100\n",
    "\n",
    "rewards_lst_1 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    ob = env.reset()\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "\n",
    "    while not done:\n",
    "        # random action as policy\n",
    "        action = env.action_space.sample()\n",
    "        # print(\"step: \", env.count)\n",
    "        # print(\"charging costs: \", env.bats_charge_costs)\n",
    "        # print(\"discharging costs: \", env.bats_discharge_costs)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    # print(\"episode {} mean reward: {}\".format(i, np.mean(rewards)))\n",
    "    rewards_lst_1.append(np.sum(rewards))\n",
    "\n",
    "# print(rewards_lst_1)\n",
    "# plot episode # versus total episode reward\n",
    "plt.bar(list(range(episodes)), rewards_lst_1, width=0.5)\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #') \n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=6'>7</a>\u001b[0m \u001b[39m# the noise objects for DDPG\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=7'>8</a>\u001b[0m \u001b[39m# n_actions = env.action_space.shape[-1]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=8'>9</a>\u001b[0m \u001b[39m# action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=9'>10</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m DDPG(MultiInputPolicy, env, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m200000\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mddpg_single_agent_battery_env\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-18-216-6-103.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000003vscode-remote?line=15'>16</a>\u001b[0m \u001b[39m# del model # remove to demonstrate saving and loading\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py:130\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    118\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    119\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    128\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(DDPG, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    131\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    132\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    133\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    134\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    135\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    136\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    137\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    138\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    139\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    140\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/td3/td3.py:205\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    194\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    203\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(TD3, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    206\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    207\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    208\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    209\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    210\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    211\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    212\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    213\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    214\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    215\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:354\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    351\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    353\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 354\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    355\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    356\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    357\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    358\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    359\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    360\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    361\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    362\u001b[0m     )\n\u001b[1;32m    364\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:587\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    584\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[1;32m    586\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 587\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m    589\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    590\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx][\u001b[39m\"\u001b[39m\u001b[39mterminal_observation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m obs\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/monitor.py:90\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/sustaingym/sustaingym/tests/../envs/MO_single_agent_battery_storage_env.py:310\u001b[0m, in \u001b[0;36mBatteryStorageInGridEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit\n\u001b[1;32m    309\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_type \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 310\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mcontains(action)\n\u001b[1;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    314\u001b[0m \u001b[39m# ensure selling cost (a) for charge is at least as large as buying cost (b)\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3.ddpg.policies import MultiInputPolicy\n",
    "from stable_baselines3.common.noise import OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3 import DDPG\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "# the noise objects for DDPG\n",
    "# n_actions = env.action_space.shape[-1]\n",
    "# action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\n",
    "model = DDPG(MultiInputPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=200000)\n",
    "model.save(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "episodes = 100\n",
    "\n",
    "rewards_lst_2 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_2.append(np.sum(rewards))\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.bar(list(range(episodes)), rewards_lst_2)\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #') \n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:22<00:00,  1.22it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVVElEQVR4nO3df7TcdX3n8ecLsGgBW5DAxgQM7aIVetpgI9XSdVWqqPUUtGhDVxu7duPuwhGt6wrqHqVdTtk9omvXrTUqNa38KKtYstZVkHJkrS4QYopAZEkLSCSSoK1Ae0CD7/3j+71fxuTem8nNnZl7Z56Pc+bcmc/Md+b9yb2Z13w/38/3M6kqJEkCOGDUBUiSFg5DQZLUMRQkSR1DQZLUMRQkSZ2DRl3A/jjyyCNrxYoVoy5DkhaVW2655cGqWjLdfYs6FFasWMHGjRtHXYYkLSpJ7p3pPoePJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1BlYKCQ5Jsn1SbYkuT3JuW37e5N8K8nm9vKKnm3OT7I1yZ1JThtUbZKk6Q3yPIVdwNuqalOSw4Bbklzb3veBqnpf74OTnACsBk4Eng58Mckzq+rxAdYoSeoxsD2FqtpeVZva6w8DW4Bls2xyOnBFVT1WVXcDW4GTB1WfJGlPQzmmkGQFcBJwY9t0TpJbk1yS5PC2bRlwX89m25gmRJKsTbIxycadO3cOsmxJ+2jFeX/JivP+ctRlaD8MPBSSHAp8GnhLVT0EfBj4aWAlsB24eOqh02y+x9fCVdW6qlpVVauWLJl26Q5JE8hAmh8DDYUkT6IJhEur6iqAqnqgqh6vqh8CH+WJIaJtwDE9my8H7h9kfZKkHzXI2UcBPg5sqar397Qv7XnYq4Db2usbgNVJDk5yHHA8cNOg6pMk7WmQs49OAV4PfD3J5rbtncBZSVbSDA3dA7wJoKpuT3IlcAfNzKWznXkkScM1sFCoqi8z/XGCz82yzYXAhYOqSZI0O89oliR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkDR2XPJi7gwFSVLHUJAkdQwFSVLHUJAkdQwFSTPygO3kMRQkSR1DQfvNT5PS+DAUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0ED45nO0uJjKEiSOoaCJKljKEiSOoaCJKljKEiSOgeNugA9oXemzj0X/eoIK9E4mfq78m9K/TAUpCEw8LVYOHwkSeoMLBSSHJPk+iRbktye5Ny2/Ygk1ya5q/15eM825yfZmuTOJKcNqjZJ0vQGOXy0C3hbVW1KchhwS5JrgTcA11XVRUnOA84D3pHkBGA1cCLwdOCLSZ5ZVY8PsEYtUA63SKMxsD2FqtpeVZva6w8DW4BlwOnA+vZh64Ez2uunA1dU1WNVdTewFTh5UPVJkvY0lGMKSVYAJwE3AkdX1XZoggM4qn3YMuC+ns22tW0aAtcpkgRDCIUkhwKfBt5SVQ/N9tBp2mqa51ubZGOSjTt37pyvMiVJDDgUkjyJJhAuraqr2uYHkixt718K7GjbtwHH9Gy+HLh/9+esqnVVtaqqVi1ZsmRwxUvSBBrk7KMAHwe2VNX7e+7aAKxpr68Bru5pX53k4CTHAccDNw2qPknSngY5++gU4PXA15NsbtveCVwEXJnkjcA3gdcAVNXtSa4E7qCZuXS2M4/UL2crSfNjYKFQVV9m+uMEAKfOsM2FwIWDqkmSNDvPaJ4jZ+tIGkeufTTmHFbRfHFhvX2zWP/vGQqS9oth8YRxGD1w+EiS1DEU9sJjB5ImicNH0oA4rLJvFusY/LhxT0GS1HFPYUz4KUvSfHBPQZLUMRQkSR2Hj+bBYjqguJhq1eK2UIY0+/mb9//FE9xTkCR1DAVJUsdQkKR91HtS67id4GooSJI6hoIkqWMoSJI6TkmVNFSLaarqJHJPQWNv3A4ESoNkKEiSOoaCJKljKEiSOoaCJKkz4+yjJP8dqJnur6o3D6QiSdLIzLansBG4BXgy8BzgrvayEnh84JVp4JyVI2l3M+4pVNV6gCRvAF5UVT9ob/8xcM1QqpOkIZv08xf6OXnt6cBhwHfb24e2bZKkebJQTurrJxQuAr6W5Pr29r8E3juwisbIpH/ikLT4zBoKSQ4A7gR+sb0AnFdV3x50YZI0LhbKXkA/Zg2Fqvphkour6vnA1UOqSZI0Iv0MH12T5NeBq6pqximqkqTBGsYeRz+h8LvAIcCuJI8CAaqqnjqQiqQJtZiGGDS+9hoKVXXYMAqRNHk8T2bh6WuZiySHJzk5yQumLn1sc0mSHUlu62l7b5JvJdncXl7Rc9/5SbYmuTPJaXPrjiRpf+x1TyHJ7wDnAsuBzcDzgK8CL97Lpp8APgT86W7tH6iq9+32GicAq4ETac6B+GKSZ1aVZ05r4jmspGHqZ0/hXOC5wL1V9SLgJGDn3jaqqht44oS3vTkduKKqHququ4GtwMl9bitJmif9hMKjVfUoQJKDq+obwLP24zXPSXJrO7x0eNu2DLiv5zHb2rY9JFmbZGOSjTt37jWbpKFyPSktdv2EwrYkPwn8BXBtkquB++f4eh8GfppmUb3twMVte6Z57LTTX6tqXVWtqqpVS5YsmWMZ0uI3FUCGkOZTP7OPXtVefW+71MVPAJ+fy4tV1QNT15N8FPhse3MbcEzPQ5cz9+CRJM1RPweafw/4P8BXqupL+/NiSZZW1fb25quAqZlJG4DLkryf5kDz8cBN+/Na0kLlgePJttB///2cvHYPcBbwh0kepgmIG6pq1mUvklwOvBA4Msk24D3AC5OspBkaugd4E0BV3Z7kSuAOYBdwtjOPJGn4+hk+ugS4JMk/A14L/AdgLc1y2rNtd9Y0zR+f5fEXAhfurR5J0uD0M3z0MeAE4AGavYQzgU0DrkuSNAL9DB89DTgQ+Aea8w4erKpdgyxKk2Ohj69Kk6bv2UdJng2cBlyf5MCqWj7o4qSFxC9N0iToZ/jolcC/AF4AHA78Fc0wkrQH3zilxa2f4aOXAzcAH6wqzx2QpDHWz/DR2UmeQXOw+f4kTwEOqqqHB16dxsYg9iA8k1eaf3td5iLJvwE+BXykbVpOs+SFJGnM9DN8dDbNiqU3AlTVXUmOGmhVUo9JnKHkXpBGpZ9QeKyqvp80a9YlOYgZFqvTcPnGIQ3WoCdOLMT/w/2skvqlJO8EnpLkJcD/BP7XYMuSJI1CP6HwDpov1fk6zVpFnwPePciiFjOXMpa0mM06fJTkAODWqvpZ4KPDKUnaP8M+BrFYz81YrHVrsGbdU6iqHwJ/k+TYIdUjSRqhfg40LwVuT3IT8I9TjVX1awOraoI41LRv/PdanObr9zaJM9GGrZ9QuGDgVUiSFoR+zmjer29bkzR4foLWfOlnT0GLjEMsmkk/B5c9AD3Z+pmSKk0UpxVrkhkKkqTOjMNHSb7O9MtZBKiq+rmBVSVJGonZjim8cmhVSFIPD5yPzoyhUFX3DrMQLRweaBwej11ooenn+xSel+TmJI8k+X6Sx5M8NIziJEnD1c+U1A8Bq2lWR10F/BbwzwdZ1Djy07fmg3sWGrS+zlOoqq1JDqyqx4E/SfKVAdelBcIwkyZLP6HwT0l+DNic5L8C24FDBlvWcCyWNzwPukmTa9h7h/2cp/D69nHn0CyIdwzw6kEWJUkajX5C4YyqerSqHqqqC6rqd3G6qiSNpX5CYc00bW+Y5zokSQvAbGc0nwX8JnBckg09dz0V+M6gC5t0zjJZGBbLcSdpvsx2oPkrNAeVjwQu7ml/GLh1kEUtVL5BSBp3ezuj+V7g+UmOBp7b3rWlqnYNozhpkAx5aU/9nNH8GuAm4DXAa4Ebk5zZx3aXJNmR5LaetiOSXJvkrvbn4T33nZ9ka5I7k5w2t+5IkvZHPwea3w08t6rWVNVvAScD/6mP7T4BvGy3tvOA66rqeOC69jZJTqA5a/rEdps/SnJgXz3Q0Pg9A+NrX3+3/i2Mr35C4YCq2tFz+zv9bFdVNwDf3a35dGB9e309cEZP+xVV9VhV3Q1spQkfaUHyTVHjqp8zmj+f5AvA5e3t3wD+9xxf7+iq2g5QVduTHNW2LwP+b8/jtrVte0iyFlgLcOyxx86xDEnSdPYaClX19iSvBn6Z5gt21lXVZ+a5jkz30jPUsw5YB7Bq1appH6OFbSF+wvags9TYaygk+S9V9Q7gqmna9tUDSZa2ewlLgalhqW00y2dMWQ7cP4fnlyTth36OKbxkmraXz/H1NvDEGdJrgKt72lcnOTjJccDxNDOehsYxYkma/Yzmfwf8e+CnkvSerHYY8Nd7e+IklwMvBI5Msg14D3ARcGWSNwLfpJnmSlXdnuRK4A5gF3B2u0z3SDiUML783Uqzm2346DKaA8p/QDt1tPVwVe0+q2gPVXXWDHedOsPjLwQu3NvzjgPfmCQtVLOd0fw94HvATG/ummAGmzSe+jmmIEmaEIaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOv2skipJGqJRLrnjnoIkqWMoSJI6hoKkieFqyHtnKEiSOh5oXmT8lCNpkAwFSYtS7wckV+udPw4fSZI6hoIkqWMoSJI6hoI0hpx6qbkyFCRJHWcfSVrQ3OMZLvcUJEkdQ0GS+jApx2kMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHU8eU0LxiRM95MWOvcUJEkdQ0GS1BnJ8FGSe4CHgceBXVW1KskRwJ8DK4B7gNdW1d+Poj5JmlSj3FN4UVWtrKpV7e3zgOuq6njguva2JGmIFtLw0enA+vb6euCM0ZUiSZNpVKFQwDVJbkmytm07uqq2A7Q/jxpRbZI0sUY1JfWUqro/yVHAtUm+0e+GbYisBTj22GMHVZ8kTaSR7ClU1f3tzx3AZ4CTgQeSLAVof+6YYdt1VbWqqlYtWbJkWCVL0kQYeigkOSTJYVPXgZcCtwEbgDXtw9YAVw+7NkmadKMYPjoa+EySqde/rKo+n+Rm4MokbwS+CbxmBLVJ0kQbeihU1d8BPz9N+3eAU4ddjyTpCQtpSqokacQMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUWXCgkeVmSO5NsTXLeqOuRpEmyoEIhyYHA/wBeDpwAnJXkhNFWJUmTY0GFAnAysLWq/q6qvg9cAZw+4pokaWKkqkZdQyfJmcDLqup32tuvB36xqs7pecxaYG1781nAnfv5skcCD+7ncyw29nky2OfJMJc+P6Oqlkx3x0H7X8+8yjRtP5JaVbUOWDdvL5hsrKpV8/V8i4F9ngz2eTLMd58X2vDRNuCYntvLgftHVIskTZyFFgo3A8cnOS7JjwGrgQ0jrkmSJsaCGj6qql1JzgG+ABwIXFJVtw/4ZedtKGoRsc+TwT5Phnnt84I60CxJGq2FNnwkSRohQ0GS1JnYUJiE5TSSHJPk+iRbktye5Ny2/Ygk1ya5q/15+KhrnW9JDkzytSSfbW+PdZ+T/GSSTyX5Rvv7fv4E9Pmt7d/1bUkuT/LkcetzkkuS7EhyW0/bjH1Mcn77nnZnktPm8poTGQoTtJzGLuBtVfVs4HnA2W0/zwOuq6rjgeva2+PmXGBLz+1x7/MHgc9X1c8AP0/T97Htc5JlwJuBVVX1szQTU1Yzfn3+BPCy3dqm7WP7f3s1cGK7zR+173X7ZCJDgQlZTqOqtlfVpvb6wzRvFMto+rq+fdh64IyRFDggSZYDvwp8rKd5bPuc5KnAC4CPA1TV96vqHxjjPrcOAp6S5CDgx2nOaRqrPlfVDcB3d2ueqY+nA1dU1WNVdTewlea9bp9MaigsA+7rub2tbRtbSVYAJwE3AkdX1XZoggM4aoSlDcJ/A/4j8MOetnHu808BO4E/aYfMPpbkEMa4z1X1LeB9wDeB7cD3quoaxrjPPWbq47y8r01qKOx1OY1xkuRQ4NPAW6rqoVHXM0hJXgnsqKpbRl3LEB0EPAf4cFWdBPwji3/YZFbtOPrpwHHA04FDkrxutFWN3Ly8r01qKEzMchpJnkQTCJdW1VVt8wNJlrb3LwV2jKq+ATgF+LUk99AMC744yScZ7z5vA7ZV1Y3t7U/RhMQ49/lXgLuramdV/QC4CvglxrvPU2bq47y8r01qKEzEchpJQjPOvKWq3t9z1wZgTXt9DXD1sGsblKo6v6qWV9UKmt/rX1XV6xjvPn8buC/Js9qmU4E7GOM+0wwbPS/Jj7d/56fSHDMb5z5PmamPG4DVSQ5OchxwPHDTPj97VU3kBXgF8P+AvwXeNep6BtTHX6bZfbwV2NxeXgE8jWbWwl3tzyNGXeuA+v9C4LPt9bHuM7AS2Nj+rv8COHwC+nwB8A3gNuDPgIPHrc/A5TTHTH5Asyfwxtn6CLyrfU+7E3j5XF7TZS4kSZ1JHT6SJE3DUJAkdQwFSVLHUJAkdQwFSVLHUJD6kOT3kvzKPDzPI3Pc7k1J3pBkZZI/3t86pJk4JVUaoiSPVNWhc9juk8B7gFcCD1bVpfNenIR7CppQSV6X5KYkm5N8ZGqJ4SSPJLk4yaYk1yVZ0rZ/IsmZ7fWLktyR5NYk72vbntE+/tb257Ft+3FJvprk5iS/v1sNb2/bb01ywQx1vjXJZuBVNMuVXAC8y70FDYqhoImT5NnAbwCnVNVK4HHgX7V3HwJsqqrnAF+i+XTeu+0RNG/QJ1bVzwH/ub3rQ8Cftm2XAn/Ytn+QZqG65wLf7nmel9IsQ3AyzdnIv5DkBbvXWlUfAF5Cs37+SuCuqjqhqv7t/vwbSDMxFDSJTgV+Abi5/RR+Ks3y09Ast/3n7fVP0iwV0ush4FHgY0leDfxT2/584LL2+p/1bHcKzVIFU+1TXtpevgZsAn6GJiSm8xzgb5IcBvx9Xz2U5uigURcgjUCA9VV1fh+P/ZGDblW1K8nJNEGyGjgHePFetpvuwF2AP6iqj8xYZHIUcA3NevmPAmcBh7VB9utV9bd91C/tE/cUNImuA85s33SnvvP2Ge19BwBnttd/E/hy74btd1P8RFV9DngLzdAPwFdoQgKaoaip7f56t/YpXwD+dft8JFk2Vc+UqtrRDhltohlm+iTw21W10kDQoLinoIlTVXckeTdwTZIDaFagPBu4l+YLak5McgvwPZpjD70OA65O8mSaT/tvbdvfDFyS5O0034L22237ucBlSc6lOVA8VcM17bGNrzYrP/MI8Dp2W/+/PQD+tKp6MMkvAb1LoEvzzimpUo+5ThmVxoXDR5KkjnsKkqSOewqSpI6hIEnqGAqSpI6hIEnqGAqSpM7/B5idgEDIRnu0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "# model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "# model.learn(total_timesteps=200000)\n",
    "# model.save(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "episodes = 100\n",
    "\n",
    "rewards_lst_4 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_4.append(np.sum(rewards))\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.bar(list(range(episodes)), rewards_lst_4)\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #') \n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sustaingym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c910351b0c3a4aade2cf03b555240fe9951314ae7b50b4f56bc279231ceafe8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
