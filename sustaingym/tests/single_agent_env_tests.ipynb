{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:272: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing environment with stable_baselines3 library\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from envs.MO_single_agent_battery_storage_env import BatteryStorageInGridEnv\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.48s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing RL agent which randomly chooses actions\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import gym\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05')\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_1 = []\n",
    "off_line_rewards_lst_1 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    ob = env.reset(seed=i)\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "\n",
    "    while not done:\n",
    "        # random action as policy\n",
    "        action = env.action_space.sample()\n",
    "        # print(\"step: \", env.count)\n",
    "        # print(\"charging costs: \", env.bats_charge_costs)\n",
    "        # print(\"discharging costs: \", env.bats_discharge_costs)\n",
    "        # print(\"env load: \", env.load_demand)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    # print(\"episode {} mean reward: {}\".format(i, np.mean(rewards)))\n",
    "    rewards_lst_1.append(np.sum(rewards))\n",
    "    ob = env.reset(seed=i)\n",
    "    off_line_rewards_lst_1.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(list(range(episodes)), rewards_lst_1, width=0.5)\n",
    "plt.title(\"Random Actions\")\n",
    "\n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "# plot episode # versus total offline episode reward\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(list(range(episodes)), off_line_rewards_lst_1, width=0.5)\n",
    "plt.title(\"Offline Optimal\")\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.70s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, StopTrainingOnNoModelImprovement\n",
    "# from stable_baselines3.common.monitor import Monitor\n",
    "# from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "\n",
    "# class PlottingCallback(BaseCallback):\n",
    "#     \"\"\"\n",
    "#     Callback for plotting the performance in realtime.\n",
    "\n",
    "#     :param verbose: (int)\n",
    "#     \"\"\"\n",
    "#     def __init__(self, verbose=1):\n",
    "#         super(PlottingCallback, self).__init__(verbose)\n",
    "#         self._plot = None\n",
    "\n",
    "#     def _on_step(self) -> bool:\n",
    "#         # get the monitor's data\n",
    "#         x, y = ts2xy(load_results(log_dir), 'timesteps')\n",
    "#         if self._plot is None: # make the plot\n",
    "#             plt.ion()\n",
    "#             fig = plt.figure(figsize=(6,3))\n",
    "#             ax = fig.add_subplot(111)\n",
    "#             line, = ax.plot(x, y)\n",
    "#             self._plot = (line, ax, fig)\n",
    "#             plt.show()\n",
    "#         else: # update and rescale the plot\n",
    "#             self._plot[0].set_data(x, y)\n",
    "#             self._plot[-2].relim()\n",
    "#             self._plot[-2].set_xlim([self.locals[\"total_timesteps\"] * -0.02, \n",
    "#                                     self.locals[\"total_timesteps\"] * 1.02])\n",
    "#             self._plot[-2].autoscale_view(True,True,True)\n",
    "#             self._plot[-1].canvas.draw()\n",
    "\n",
    "# # Create log dir\n",
    "# log_dir = \"/tmp/gym/\"\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# env = BatteryStorageInGridEnv(date='2019-05')\n",
    "\n",
    "# stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "# eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "# model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "# model.learn(int(1e10), callback=[eval_callback, PlottingCallback()])\n",
    "# model.save(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "# model = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "# episodes = 10\n",
    "\n",
    "# rewards_lst_4 = []\n",
    "# off_line_rewards_lst_4 = []\n",
    "\n",
    "# for i in tqdm(range(episodes)):\n",
    "#     obs = env.reset(seed=i)\n",
    "#     done = False\n",
    "#     start = True\n",
    "#     rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "#     avg = np.zeros(1)\n",
    "#     while not done:\n",
    "#         action, _states = model.predict(obs)\n",
    "#         if action.shape[0] == 1:\n",
    "#             action = action.reshape((2,))\n",
    "#         obs, reward, done, info = env.step(action)\n",
    "#         rewards[env.count - 1] = reward\n",
    "#     rewards_lst_4.append(np.sum(rewards))\n",
    "#     ob = env.reset(seed=i)\n",
    "#     off_line_rewards_lst_4.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# # plot episode # versus total episode reward\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.bar(list(range(episodes)), rewards_lst_4, width=0.5)\n",
    "# plt.title(\"Random Actions\")\n",
    "\n",
    "# # naming the y axis \n",
    "# plt.ylabel('total reward')\n",
    "\n",
    "# # plot episode # versus total offline episode reward\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.bar(list(range(episodes)), off_line_rewards_lst_4, width=0.5)\n",
    "# plt.title(\"Offline Optimal\")\n",
    "\n",
    "# # naming the x axis \n",
    "# plt.xlabel('episode #')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000004vscode-remote?line=14'>15</a>\u001b[0m \u001b[39m# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000004vscode-remote?line=15'>16</a>\u001b[0m model \u001b[39m=\u001b[39m DDPG(\u001b[39m\"\u001b[39m\u001b[39mMultiInputPolicy\u001b[39m\u001b[39m\"\u001b[39m, env, action_noise\u001b[39m=\u001b[39maction_noise, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000004vscode-remote?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(\u001b[39mint\u001b[39;49m(\u001b[39m1e10\u001b[39;49m), callback\u001b[39m=\u001b[39;49meval_callback)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000004vscode-remote?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mddpg_single_agent_battery_env\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000004vscode-remote?line=19'>20</a>\u001b[0m \u001b[39m# del model # remove to demonstrate saving and loading\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py:130\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    118\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    119\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    128\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    131\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    132\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    133\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    134\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    135\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    136\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    137\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    138\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    139\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    140\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/td3/td3.py:211\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    200\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    212\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    213\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    214\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    215\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    216\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    217\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    218\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    219\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    220\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:346\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    343\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    345\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 346\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    347\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    348\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    349\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    350\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    351\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    352\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    353\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    354\u001b[0m     )\n\u001b[1;32m    356\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:579\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    576\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[1;32m    578\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m    581\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    582\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx][\u001b[39m\"\u001b[39m\u001b[39mterminal_observation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m obs\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/monitor.py:90\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/sustaingym/sustaingym/tests/../envs/MO_single_agent_battery_storage_env.py:462\u001b[0m, in \u001b[0;36mBatteryStorageInGridEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit\n\u001b[1;32m    461\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_type \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 462\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mcontains(action)\n\u001b[1;32m    464\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    466\u001b[0m \u001b[39m# ensure selling cost (a) for charge is at least as large as buying cost (b)\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from stable_baselines3.ddpg.policies import MultiInputPolicy\n",
    "# from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "# from stable_baselines3 import DDPG\n",
    "# import numpy as np\n",
    "\n",
    "# env = BatteryStorageInGridEnv(date='2019-05')\n",
    "\n",
    "# stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "# eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "# # the noise objects for DDPG\n",
    "# n_actions = env.action_space.shape[-1]\n",
    "# action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# # model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\n",
    "# model = DDPG(\"MultiInputPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "# model.learn(int(1e10), callback=eval_callback)\n",
    "# model.save(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "# # del model # remove to demonstrate saving and loading\n",
    "\n",
    "# model = DDPG.load(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "# episodes = 10\n",
    "\n",
    "# rewards_lst_2 = []\n",
    "# off_line_rewards_lst_2 = []\n",
    "\n",
    "# for i in tqdm(range(episodes)):\n",
    "#     obs = env.reset(seed=i)\n",
    "#     done = False\n",
    "#     start = True\n",
    "#     rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "#     avg = np.zeros(1)\n",
    "#     while not done:\n",
    "#         action, _states = model.predict(obs)\n",
    "#         if action.shape[0] == 1:\n",
    "#             action = action.reshape((2,))\n",
    "#         obs, reward, done, info = env.step(action)\n",
    "#         rewards[env.count - 1] = reward\n",
    "#     rewards_lst_2.append(np.sum(rewards))\n",
    "#     ob = env.reset(seed=i)\n",
    "#     off_line_rewards_lst_2.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# # plot episode # versus total episode reward\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.bar(list(range(episodes)), rewards_lst_2, width=0.5)\n",
    "# plt.title(\"Random Actions\")\n",
    "\n",
    "# # naming the y axis \n",
    "# plt.ylabel('total reward')\n",
    "\n",
    "# # plot episode # versus total offline episode reward\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.bar(list(range(episodes)), off_line_rewards_lst_2, width=0.5)\n",
    "# plt.title(\"Offline Optimal\")\n",
    "\n",
    "# # naming the x axis \n",
    "# plt.xlabel('episode #')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 287      |\n",
      "|    ep_rew_mean        | 2.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 209      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | -24.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0143  |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.07e-05 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1000, episode_reward=2409.92 +/- 74.85\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.41e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -1.13    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.0393   |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 0.000208 |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 287      |\n",
      "|    ep_rew_mean     | 2.5e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 200      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 1000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 322      |\n",
      "|    ep_rew_mean        | 3.13e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -5.55    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.014    |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 6.81e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=2575.21 +/- 170.36\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.58e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | 0.105    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.00405 |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 1.11e-05 |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 310      |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 400      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 2000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | 3.15e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -0.133   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.0408   |\n",
      "|    std                | 0.995    |\n",
      "|    value_loss         | 0.0003   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=2389.82 +/- 72.68\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.39e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.82    |\n",
      "|    explained_variance | -9.92    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.00152  |\n",
      "|    std                | 0.99     |\n",
      "|    value_loss         | 2.03e-05 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 318      |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 600      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 3000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 329      |\n",
      "|    ep_rew_mean        | 3.16e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.82    |\n",
      "|    explained_variance | -10.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.00836 |\n",
      "|    std                | 0.993    |\n",
      "|    value_loss         | 4.37e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=2420.96 +/- 121.50\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.42e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.81    |\n",
      "|    explained_variance | -2.85    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.0161  |\n",
      "|    std                | 0.988    |\n",
      "|    value_loss         | 5.22e-05 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 322      |\n",
      "|    ep_rew_mean     | 3.06e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 800      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 4000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 330      |\n",
      "|    ep_rew_mean        | 3.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -4.68    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.0241   |\n",
      "|    std                | 0.995    |\n",
      "|    value_loss         | 0.000149 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=2647.75 +/- 131.91\n",
      "Episode length: 287.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 287       |\n",
      "|    mean_reward        | 2.65e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.83     |\n",
      "|    explained_variance | -1.65e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -0.00385  |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 2.84e-06  |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 324      |\n",
      "|    ep_rew_mean     | 3.11e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 5000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 330      |\n",
      "|    ep_rew_mean        | 3.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | -60.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.0194  |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.69e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=2486.03 +/- 110.32\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.49e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | -59.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.00691 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.00012  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 326      |\n",
      "|    ep_rew_mean     | 3.17e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 1200     |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 6000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 331      |\n",
      "|    ep_rew_mean        | 3.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.646   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.0219  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.92e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=2426.43 +/- 60.56\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.43e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -0.0437  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.0192   |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 3.9e-05  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | 3.19e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 1400     |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 7000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 331      |\n",
      "|    ep_rew_mean        | 3.28e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | 0.0276   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.00426 |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 3.72e-06 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=2424.62 +/- 146.32\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.42e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | 0.363    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.013   |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.62e-05 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 328      |\n",
      "|    ep_rew_mean     | 3.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 1600     |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 8000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 331      |\n",
      "|    ep_rew_mean        | 3.29e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | -3.84    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.0104   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.28e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=2547.32 +/- 138.80\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.55e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -0.275   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.0194   |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 8.57e-05 |\n",
      "------------------------------------\n",
      "Stopping training because there was no new best model in the last 4 evaluations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.78s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05')\n",
    "\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "model = A2C(\"MultiInputPolicy\", env, verbose=1)\n",
    "model.learn(int(1e10), callback=eval_callback)\n",
    "model.save(\"a2c_single_agent_battery_env\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"a2c_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_3 = []\n",
    "off_line_rewards_lst_3 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i)\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_3.append(np.sum(rewards))\n",
    "    ob = env.reset(seed=i)\n",
    "    off_line_rewards_lst_3.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(list(range(episodes)), rewards_lst_3, width=0.5)\n",
    "plt.title(\"Random Actions\")\n",
    "\n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "# plot episode # versus total offline episode reward\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(list(range(episodes)), off_line_rewards_lst_3, width=0.5)\n",
    "plt.title(\"Offline Optimal\")\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:08<00:19,  2.72s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (1, 2)) of distribution Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan]], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000006vscode-remote?line=17'>18</a>\u001b[0m rewards \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(env1\u001b[39m.\u001b[39mMAX_STEPS_PER_EPISODE)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000006vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000006vscode-remote?line=19'>20</a>\u001b[0m     action, _states \u001b[39m=\u001b[39m model_ppo\u001b[39m.\u001b[39;49mpredict(obs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000006vscode-remote?line=20'>21</a>\u001b[0m     \u001b[39mif\u001b[39;00m action\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000006vscode-remote?line=21'>22</a>\u001b[0m         action \u001b[39m=\u001b[39m action\u001b[39m.\u001b[39mreshape((\u001b[39m2\u001b[39m,))\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/base_class.py:579\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    561\u001b[0m     observation: np\u001b[39m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    564\u001b[0m     deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    565\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, Optional[Tuple[np\u001b[39m.\u001b[39mndarray, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]]:\n\u001b[1;32m    566\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mpredict(observation, state, episode_start, deterministic)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/policies.py:338\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    335\u001b[0m observation, vectorized_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_to_tensor(observation)\n\u001b[1;32m    337\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 338\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(observation, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[1;32m    339\u001b[0m \u001b[39m# Convert to numpy\u001b[39;00m\n\u001b[1;32m    340\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/policies.py:630\u001b[0m, in \u001b[0;36mActorCriticPolicy._predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, observation: th\u001b[39m.\u001b[39mTensor, deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    623\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[39m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_distribution(observation)\u001b[39m.\u001b[39mget_actions(deterministic\u001b[39m=\u001b[39mdeterministic)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/policies.py:659\u001b[0m, in \u001b[0;36mActorCriticPolicy.get_distribution\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    657\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs)\n\u001b[1;32m    658\u001b[0m latent_pi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_extractor\u001b[39m.\u001b[39mforward_actor(features)\n\u001b[0;32m--> 659\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_action_dist_from_latent(latent_pi)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/policies.py:607\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    604\u001b[0m mean_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_net(latent_pi)\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[0;32m--> 607\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_dist\u001b[39m.\u001b[39;49mproba_distribution(mean_actions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_std)\n\u001b[1;32m    608\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[1;32m    609\u001b[0m     \u001b[39m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[1;32m    610\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist\u001b[39m.\u001b[39mproba_distribution(action_logits\u001b[39m=\u001b[39mmean_actions)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/distributions.py:153\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m:return:\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m action_std \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mones_like(mean_actions) \u001b[39m*\u001b[39m log_std\u001b[39m.\u001b[39mexp()\n\u001b[0;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution \u001b[39m=\u001b[39m Normal(mean_actions, action_std)\n\u001b[1;32m    154\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/torch/distributions/normal.py:50\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     batch_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc\u001b[39m.\u001b[39msize()\n\u001b[0;32m---> 50\u001b[0m \u001b[39msuper\u001b[39;49m(Normal, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(batch_shape, validate_args\u001b[39m=\u001b[39;49mvalidate_args)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/torch/distributions/distribution.py:55\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m         valid \u001b[39m=\u001b[39m constraint\u001b[39m.\u001b[39mcheck(value)\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid\u001b[39m.\u001b[39mall():\n\u001b[0;32m---> 55\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected parameter \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof distribution \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mto satisfy the constraint \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(constraint)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found invalid values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[39msuper\u001b[39m(Distribution, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter loc (Tensor of shape (1, 2)) of distribution Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan]], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "# Get rewards for Testing on May 2021\n",
    "\n",
    "model_ppo = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "model_a2c = PPO.load(\"a2c_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_ppo_21_5 = []\n",
    "rewards_lst_a2c_21_5 = []\n",
    "off_line_rewards_lst_21_5 = []\n",
    "\n",
    "env1 = BatteryStorageInGridEnv(date='2021-05')\n",
    "env2 = BatteryStorageInGridEnv(date='2021-05')\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env1.reset(seed=i)\n",
    "    done = False\n",
    "    rewards = np.zeros(env1.MAX_STEPS_PER_EPISODE)\n",
    "    while not done:\n",
    "        action, _states = model_ppo.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env1.step(action)\n",
    "        rewards[env1.count - 1] = reward\n",
    "    \n",
    "    obs2 = env2.reset(seed=i)\n",
    "    done2 = False\n",
    "    rewards2 = np.zeros(env2.MAX_STEPS_PER_EPISODE)\n",
    "    while not done2:\n",
    "        action, _states = model_a2c.predict(obs2)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs2, reward, done2, info = env2.step(action)\n",
    "        rewards2[env2.count - 1] = reward\n",
    "    rewards_lst_ppo_21_5.append(np.sum(rewards))\n",
    "    rewards_lst_a2c_21_5.append(np.sum(rewards2))\n",
    "    ob = env1.reset(seed=i)\n",
    "    off_line_rewards_lst_21_5.append(env1._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "print(\"2021/5 PPO: \", rewards_lst_ppo_21_5)\n",
    "print(\"2021/5 A2C: \", rewards_lst_a2c_21_5)\n",
    "print(\"2021/5 Offline Optimal: \", off_line_rewards_lst_21_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate evaluation for PPO trained on May 2019 and tested on May 2019 (in-dist)\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05', seed=195)\n",
    "\n",
    "model_ppo = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_ppo_19_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    while not done:\n",
    "        action, _states = model_ppo.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_ppo_19_5.append(np.sum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate evaluation for A2C trained on May 2019 and tested on May 2019 (in-dist)\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05', seed=195)\n",
    "\n",
    "model_a2c = A2C.load(\"a2c_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_a2c_19_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    while not done:\n",
    "        action, _states = model_a2c.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_a2c_19_5.append(np.sum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate off-line optimal values for May 2019\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05', seed=195)\n",
    "\n",
    "offline_optimal_19_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    offline_optimal_19_5.append(env._calculate_off_optimal_total_episode_reward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate evaluation for PPO trained on May 2019 and tested on May 2021 (out-dist)\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2021-05', seed=215)\n",
    "\n",
    "model_ppo_out = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_ppo_21_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    while not done:\n",
    "        action, _states = model_ppo_out.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_ppo_21_5.append(np.sum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate evaluation for A2C trained on May 2019 and tested on May 2021 (out-dist)\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2021-05', seed=215)\n",
    "\n",
    "model_a2c_out = A2C.load(\"a2c_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_a2c_21_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    while not done:\n",
    "        action, _states = model_a2c_out.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_a2c_21_5.append(np.sum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate off-line optimal values for May 2019\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2021-05', seed=215)\n",
    "\n",
    "offline_optimal_21_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    offline_optimal_21_5.append(env._calculate_off_optimal_total_episode_reward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/5 PPO:  [2245.0145741723068, 2558.4557707267295, 2536.6470375887716, 2213.9489259221714, 2545.763597560765, 2602.458985199197, 2372.820422435832, 2548.4725186985274, 2261.2602848462757, 2779.4824376099523]\n",
      "2019/5 A2C:  [2245.0145743153016, 2558.4557716921063, 2536.647038219378, 2213.948927097822, 2545.763598501142, 2602.458988265422, 2372.82042346052, 2548.472526844007, 2261.2602856102226, 2779.4824385186284]\n",
      "2019/5 Offline Optimal:  [23051.710297436803, 18248.597237755643, 18994.697055206787, 22868.55334810844, 16514.00674815259, 33131.47019110864, 14612.253560855821, 22389.303426021896, 23079.613407532303, 23031.783863923756]\n",
      "2021/5 PPO:  [2743.0189450456783, 2609.6690354598877, 2641.4290383788198, 2714.706752567427, 2342.052034742505, 2732.207455008233, 2753.6307763219734, 2784.0557684839923, 2722.8755581028713, 2835.9102791492815]\n",
      "2021/5 A2C:  [2743.0189478052616, 2609.6690381383055, 2641.42903982744, 2714.7067542683335, 2342.0520677395284, 2732.207453737356, 2753.6307779419335, 2784.0557688661515, 2722.8755588359236, 2835.9102810094723]\n",
      "2021/5 Offline Optimal:  [20482.670758292246, 19429.36173842518, 16713.67791627479, 22916.353857972834, 18087.993419986706, 20595.192383295172, 17483.9390511944, 21319.578990298218, 22556.99662278885, 21071.943076509524]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"2019/5 PPO: \", rewards_ppo_19_5)\n",
    "print(\"2019/5 A2C: \", rewards_a2c_19_5)\n",
    "print(\"2019/5 Offline Optimal: \", offline_optimal_19_5)\n",
    "print(\"2021/5 PPO: \", rewards_ppo_21_5)\n",
    "print(\"2021/5 A2C: \", rewards_a2c_21_5)\n",
    "print(\"2021/5 Offline Optimal: \", offline_optimal_21_5)\n",
    "\n",
    "models = ['Offline', 'PPO', 'A2C']\n",
    "in_dist = [np.mean(offline_optimal_19_5), np.mean(rewards_ppo_19_5), np.mean(rewards_a2c_19_5)]\n",
    "out_dist = [np.mean(offline_optimal_21_5), np.mean(rewards_ppo_21_5), np.mean(rewards_a2c_21_5)]\n",
    "\n",
    "x_axis = np.arange(len(models))\n",
    "\n",
    "plt.bar(x_axis - 0.2, in_dist, width=0.4, label='In-Dist', color='blue')\n",
    "plt.bar(x_axis + 0.2, out_dist, width=0.4, label='Out-Dist', color='orange')\n",
    "\n",
    "in_dist_err = [np.std(offline_optimal_19_5), np.std(rewards_ppo_19_5), np.std(rewards_a2c_19_5)]\n",
    "out_dist_err = [np.std(offline_optimal_21_5), np.std(rewards_ppo_21_5), np.std(rewards_a2c_21_5)]\n",
    "\n",
    "plt.errorbar(x_axis - 0.2, in_dist, yerr=in_dist_err, fmt='o', color='gray')\n",
    "plt.errorbar(x_axis + 0.2, out_dist, yerr=out_dist_err, fmt='o', color='gray')\n",
    "\n",
    "plt.xticks(x_axis, models)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sustaingym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c910351b0c3a4aade2cf03b555240fe9951314ae7b50b4f56bc279231ceafe8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
