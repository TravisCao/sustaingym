{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:272: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing environment with stable_baselines3 library\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from envs.MO_single_agent_battery_storage_env import BatteryStorageInGridEnv\n",
    "\n",
    "env = BatteryStorageInGridEnv()\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.46s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEWCAYAAABfdFHAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAta0lEQVR4nO3dfZzVZZ3/8dcbzJsVVEBABAn7pYmIkYygW1sQjpIZ5R3qVmKr68bPttItw2x/oGVLbuZNdLNuspLmTduui7sgBrjWViKijAm4JiTW6IQg3oC33Hx+f3yvA4fhzMyZmfOdOTO8n4/HeXDOdX2/51zn8D3zOd/r+nyvSxGBmZlZXnp0dgPMzKx7c6AxM7NcOdCYmVmuHGjMzCxXDjRmZpYrBxozM8uVA80eRtIMSbd3djtaS9JmSe/q7HZYvpT5F0kvSVqayqZKWpeOgX6SQtK7U90PJf1957a6fHm2t/hzqTYONFVA0lpJb6Qv0p8k3SqpV2e3qxIkHS5pu6Tvt2KfByVdVFwWEb0i4veVb6F1JEkXSHpC0uvpWP+BpIOKNvkAUAsMiYgxkt4BfAc4OR0DLxY/X0R8NiK+nlNbh0j6iaQXJb0maamk01qx/wWSflVclmd7q5kDTfX4WET0AkYB7wOu6NzmVMz5wEvAuZL26ezGWOeR9HfAt4AvAwcCJwDvBBZK2jtt9k5gbUS8lh4PBPYFVnZwW/sCvwLeBkYABwPXA3dIOqsj29ItRIRvnXwD1gInFT2+FphX9HgasAbYBKwCTi+qu4DsC/Ftsj/ozwAfKao/HPhF2nchMAu4vah+EtmX+GXgQWB4o3Z9Gfgt8BpwC9kX/770fIuAPi28tzXAVGAdcFajuo8DdcCrabuJwDXANuBNYDMwK20bwLvT/QOBHwPrgWeBrwE9yvw8LgB+n9r/DPDJzv7/3xNuwAHp/3Nyo/JewAvAXwEXpv/3bWnbO9NxF+nxAyWOhVuBb6T744B64O/SczYAnyl6rX3ScfGHdDz+ENivifZ+HVhROK6Kyr+SjjkVteXz6ZjaAPwj2Q/44Y3ey8vNtPfyovZ+AjgV+B2wEfhq0WuPAR4i+642kH2X9y6q3/G5VNut0xvg266BBhgCPAHcWFR/NnBoOoDPSV++QanuAmAL8NdAT7I/6s8XfREeIut62Af4YPoDe3uqOzI9Vy3wjnTAry4cvKldS8iCy+D0ZXiM7IxrH+ABYHoz7+svgLeAPsB3gXuL6sYAr6TX7pGe/6hU9yBwUaPnKv7j8mNgLtAbGJa+lBe29HkA+5MFtfekbQcBIzr7/39PuJH9iNgK7FWibg5wZ9H/36+K6oal//u9isqaCzRbgavT8Xwq8DrpxxBwA3Av0DcdO/8J/EMT7V0CXFWi/PD0+u8past/p+ccmo7Fi0q9l2ba+/9Se/+a7MfTHal9I8iC1bvS9qPJzgL3Sp/Lk8AXS30u1XZz11n1+A9Jm4A/kv1Bn16oiIh/jYjnI2J7RNwNPE32h7rg2Yj454jYRvalHQQMlDQUOB74+4h4KyJ+SfblKjiH7MxpYURsIfu1tx/w50XbfDci1kXEc8D/AA9HxPKIeAu4hyzoNGUKcF9EvET25fmIpAGp7kJgdnrt7RHxXET8b0sfkqSeqd1XRMSmiFgLXAd8uqXPI9VtB46RtF9ENEREh3bJ7MEOBjZExNYSdQ2pvhK2AFdHxJaImE92NvEeSSL7Q35pRGyMiE3AN4Fzm2lvQxNtLdQXfCs95x/Igtl5rWzvNen7d1d63hvTsb2SrLfhWICIeDQilkTE1nTc/xPwoVa8VqdxoKken4iI3mS/co6i6ECWdL6kOkkvS3oZOIZdD/Q/Fe5ExOvpbi+ys6CXYmd/N2Sn/QWHFj+OiO1kgW5w0Tbriu6/UeJxyaQFSfuRnYn9JD33Q2RdFn+ZNjmMrLustQ4G9m70Pp5t1OaSn0f6HM4BPgs0SJon6ag2tMFabwNwsKS9StQNSvWV8GKjYPY62THaH/gz4NGi79GCVN5Uewc10dZCfcEfi+4/S/a9ak17t6X7b6R/S37HJB0p6b9SEsWrZIGyUgE6Vw40VSYifkF2ev1tAEnvBP4Z+BzQLyIOIus7VhlP1wD0kbR/UdnQovvPkw2+kl5LZAHguba/gx1OJ+uX/376YvyJLBicn+r/CPyfJvZtbkrxDWS/At9ZVDaUMtscEfdHRC3ZH4z/JftsLX8PkXWjnlFcmI7NjwCLc379DWR/tEdExEHpdmBkCTilLALOlNT4b+RksmP3d0VlhxXdH0r2vYLmj+O2+AHZMXtERBwAfJXy/g50Ogea6nQDUCtpFNm4QpD13SLpM2RnNC2KiGeBZcBVkvaW9AHgY0Wb/BT4qKQJKY3078j+GPymAu9hCjAbGEmWSTcKeD8wStJIssSCz6TX7iFpcNHZxTqg5DUz6dffT4FrJPVOgfgyoMVrgyQNlDQp/XF7i6xbZVsLu1kFRMQrwFXAdyVNlPQOScOAfyUbEL8t59ffTvaj4vpC92065k5pYpfryX4o3SLpEEn7SjoPuBL4cqRBkeTLkvpIOgz4AnB3Kl8HDCnKqGuv3mRjjJvTd2VqhZ43dw40VSgi1pMNeP99RKwiG4N4iOzAHQn8uhVP95fAWLIMlunpeQuv8xTwKbKB+g1kQehjEfF2e9ovaTAwAbghIv5UdHuUrLtiSkQsBT5D9oV+hSwzrnCWciNwVrpo76YSL/G3ZEkMvyfLMLuDLKi1pAdZMH2e7PP4EPB/2/g2rZUi4lqyX+HfJvuD+TDZ2cGENOaXt6+QJbssSV1Pi4D3NNHWF8mu6dmXLNPzRbIfNJ9O46TF5gKPkmVQziP7EQVZssxK4E+SKtE1+CWy7/MmsqDZuB1VS7sGZjMzK5ekIOvKWt3ZbalmPqMxM7Nc7RGBJvUJPyVptaRpnd0eM7M9SbfvOkvXXfyO7MLAeuAR4Lw09mFmZjnbE85oxgCrI+L3aZD7LrKpT8zMrAOUuniquxnMrhdU1ZNlYe0g6WLgYoD9999/9FFHlb6G74nnXmn2hUYOPrDJuub2bet+eb1me/atttdsz755veajjz66ISKaulAwNwcffHAMGzaso1/W9hDNHdd7QqApdUHTLv2FEXEzcDNATU1NLFu2rOQTDZs2r9kXWjbzo03WNbdvW/fL6zXbs2+1vWZ79s3rNSU922RljoYNG0ZTx7ZZezV3XO8JXWf17Hrl7hB2XrlrZmY52xMCzSPAEWkBrr3JJtG7t5PbZGa2x+j2XWcRsVXS54D7yaaNn+0Ze83MOk63DzQAabrw+Z3dDjOzPdGe0HVmZmadyIHGzMxy5UBjZma5cqAxM7NcOdCYmVmu9oisMzNrXnMzHaxtYUYHs5b4jMbMzHLlQGNmZrlyoDHLybZt23jf+97HaaedBsDGjRupra0FOEbSQkl9CttKuiItzPeUpFOKykdLeiLV3SRJqXwfSXen8oclDevYd2dWPgcas5zceOONDB8+fMfjmTNnMmHCBIAVwGJgGoCko8nm4BsBTAS+nxbsA/gB2RIWR6TbxFR+IfBSRLwbuB74Vt7vx6ytHGjMclBfX8+8efO46KKLdpTNnTuXKVOmFB7OAT6R7n8cuCsi3oqIZ4DVwBhJg4ADIuKhyJbC/XGjfeak+z8DJhTOdsyqjQONWQ6++MUvcu2119Kjx86v2Lp16xg0aBAAEdEADEhVpRbnG5xu9SXKd9knIrYCrwD9GrdD0sWSlklatn79+gq8M7PWc6Axq7DXVy9lwIABjB49utxdmlqcr7lF+1pc0A+yRf0ioiYiavr37/BFPc0AX0djVnFvPbeKe5c8xPz583nzzTd59dVX+dSnPsXAgQNpaGgAIHWLvZB2aWpxvvp0v3F58T71kvYCDgQ25vamzNrBZzRmFdbnQxdQX1/P2rVrueuuu/jwhz/M7bffzqRJk5gzpzCswhRgbrp/L3BuyiQ7nGzQf2nqXtsk6YQ0/nJ+o30KAz5nAQ+kcRyzquMzGrMOMm3aNCZPngxwDNmYytkAEbFS0k+BVcBW4JKI2JZ2mwrcCuwH3JduALcAt0laTXYmc24HvY3deFYBa0nVBRpJ/wh8DHgbWAN8JiJeTnVXkKV1bgM+HxH3p/LR7Pwyzge+EBEhaR+yTJ3RwIvAORGxtiPfj+3Zxo0bx7hx4wDo168fixcvRtKKiJhQvF1EXANc03j/iFhGFpgal79JClRm1a4au84WAsdExLHA74ArwNcamJl1VVUXaCLi5yldE2AJOwdDfa2BmVkXVHWBppG/YmeftK81MDPrgjpljEbSIuCQElVXRsTctM2VZAOjPynsVmL7il1rANwMUFNT48wdM7MK6pRAExEnNVcvaQpwGjChKGXT1xqYmXVBVdd1Jmki8BVgUkS8XlTlaw3MzLqgqktvBmYB+wAL07j9koj4bFe/1sDMbE9VdYEmpSI3VedrDczMupiq6zozM7PuxYHGzMxy5UBjZma5cqAxM7NcOdCYmVmuHGjMzCxXDjRmZpYrBxozM8uVA41ZhcXWtxkzZgzvfe97GTFiBNOnTwdgxowZDB48GOBoSXWSTi3sI+kKSaslPSXplKLy0ZKeSHU3FZa5SFMx3Z3KH5Y0rGPfpVn5HGjMKq3nO3jggQd4/PHHqaurY8GCBSxZsgSASy+9FGBVRIyKiPngRf2s+3OgMaswSfTq1QuALVu2sGXLFlpYb8+L+lm35kBjloNt27YxatQoBgwYQG1tLWPHjgVg1qxZkHWdzZbUJ23uRf2sW3OgMctBz549qauro76+nqVLl7JixQqmTp3KmjVrIJuBvAG4Lm2e66J+EVETETX9+/dv/RsxqwAHGrMcHXTQQYwbN44FCxYwcOBAevYsDL3wz8CYdL89i/rhRf2s2jnQmFXYttdf4eWXXwbgjTfeYNGiRRx11FE0NDQUb3Y6sCLd96J+1q1VbaCR9CVJIengojKngFrV27Z5I+PHj+fYY4/l+OOPp7a2ltNOO43LL7+ckSNHAhwNjAcuBYiIlUBhUb8F7L6o34/IEgTWsOuifv3Son6XAdM66O2ZtVrVLXwGIOkwoBb4Q1FZcQroocAiSUemL2QhBXQJMJ8sBfQ+ilJAJZ1LlgJ6Tke+F9vz7D3gcJYvX75b+W233QaApFURMam4zov6WXdWrWc01wOXs+vgplNAzcy6oKoLNJImAc9FxOONqpwCambWBXVK15mkRcAhJaquBL4KnFxqtxJlFUsBBW4GqKmp8YCqmVkFdUqgiYiTSpVLGgkcDjyeeriGAI9JGkP7UkDrnQJqZtY5qqrrLCKeiIgBETEsIoaRBYrjIuJPOAXUzKxLqsqss1IiYqWkQgroVnZPAb0V2I8s26w4BfS2lAK6kSxrzczMOlBVB5p0VlP82CmgZmZdTFV1nZmZWffjQGNmZrlyoDEzs1w50JiZWa4caMzMLFcONGZmlisHGjMzy5UDjZmZ5cqBxszMcuVAY1ZhsfVtxowZw3vf+15GjBjB9OnTAdi4cSO1tbUAx0haKKlPYR+vHmvdmQONWaX1fAcPPPAAjz/+OHV1dSxYsIAlS5Ywc+ZMJkyYALACWExafrnR6rETge9L6pmerbB67BHpNjGV71g9lmyhwG910LszazUHGrMKk0SvXr0A2LJlC1u2bEESc+fOZcqUwmTizGHXlWC9eqx1W1U9qaZZV7Vt2zZGjx7N6tWrueSSSxg7dizr1q1j0KBBAEREg6QBafPBwJKi3QurxG6hzNVjJRVWj91Q3A5JF5OdETF06NBKvkXrpoZNm9dk3dqZH23Tc/qMxiwHPXv2pK6ujvr6epYuXcqKFSua2zzX1WMjoiYiavr3799iu83y4EBjlqODDjqIcePGsWDBAgYOHEhDQwMAqVvshbRZe1aPxavHWrVzoDGrsG2vv8LLL78MwBtvvMGiRYs46qijmDRpEnPmFIZVmMKuK8F69VjrtqpyjEbS3wKfI1tJc15EXJ7KryDLttkGfD4i7k/lo9m5wuZ84AsREZL2IRtAHQ28CJwTEWs79t3Ynmbb5o2MHz+ebdu2sX37diZPnsxpp53GiSeeyOTJkyFbpO8V0qJ8Xj22e2tuzAPaPu7RlVRdoJE0niyj5tiIeKswYNooBfRQYJGkI9MXspACuoQs0Ewk+0LuSAGVdC5ZCug5Hf2ebM+y94DDWb58+W7l/fr1Y/HixUhaERETiuu8eqx1Z9XYdTYVmBkRbwFERKEf2ymgZmZdUDUGmiOBv0hXO/9C0vGpfEc6Z1JI9RxMmSmgZN0V/Rq/oKSLJS2TtGz9+vUVfTNmZnu6Tuk6k7QIOKRE1ZVkbeoDnAAcD/xU0rvIOQUUuBmgpqbGA6pmZhXUKYEmIk5qqk7SVODfUzfYUknbgYNpXwpovVNAzcw6RzV2nf0H8GEASUcCe5Nd7ewUUDOzLqjqss6A2cBsSSuAt4EpKTg4BdTMrAuqukATEW8Dn2qizimgZmZdTDV2nZmZWTfS5BmNpO9SIkOrICI+n0uLzMysW2nujGYZ8CiwL3Ac8HS6jSKbAsbMzKxFTZ7RRMQcAEkXAOMjYkt6/EPg5x3SOjMz6/LKGaM5FOhd9LhXKjMzM2tROVlnM4Hlkv47Pf4QMCO3FpmZWbfSbKCR1AN4ChibbgDTIuJPeTfMzMy6h2YDTURsl3RdRJzIzqvtzczMylbOGM3PJZ3p6fXNzKwtygk0lwH/Crwl6VVJmyS9mnO7zLqsra+uZ/z48QwfPpwRI0Zw4403AjBjxgwGDx4McLSkOkmnFvaRdIWk1ZKeknRKUfloSU+kupsKP/jSnH93p/KHJQ3r2HdpVr4WA01E9I6IHhGxd0QckB4f0BGNM+uSevTkuuuu48knn2TJkiV873vfY9WqVQBceumlAKsiYlREzIfdVo+dCHxfUs/0bIXVY49It4mpfMfqscD1ZKvHmlWlsqagkdRH0hhJHyzc8m6YWVe1V6++HHfccQD07t2b4cOH89xzzzW3i1ePtW6txUAj6SLgl8D9wFXp3xn5Nsuse1i7di3Lly9n7NgsaXPWrFmQdZ3NltQnbebVY61bK+eM5gtkK10+GxHjgfcBPmLNWrB582bOPPNMbrjhBg444ACmTp3KmjVrIFvqogG4Lm2a6+qxEVETETX9+/dv/Zswq4ByAs2babp9JO0TEf8LvCffZpl1bVu2bOHMM8/kk5/8JGeccQYAAwcOpGfPwtAL/wyMSffbs3osXj3Wql05gaZe0kFkK18ulDSXnQd7xUkaJWlJyspZJmlMUZ0zc6zqRQQXXnghw4cP57LLLttR3tDQULzZ6cCKdN+rx1q31uIUNBFxero7I01DcyCwIMc2XQtcFRH3pfTPa4FxjTJzDgUWSToyrbJZyMxZAswny8y5j6LMHEnnkmXmnJNj281467lV3PaT2xg5ciSjRo0C4Jvf/CZ33nkndXV1AEcD44G/AYgIrx5r3VqLgUbS1cD/AL+JiF/k3yQCKKRPH8jOs6cdmTnAM+kLNkbSWlJmTmpvITPnvrTPjLT/z4BZkuRffpanfYeMoNQhduqp2WUzklZFxKTiOq8ea91ZOZNqrgXOA26StIks6PwyIvKakuaLwP2Svk3WtffnqXww2RlLQSEDZwtlZuZIKmTmbMip7WZm1kg5XWezgdmSDgEmA18i66bq3eyOzZC0CDikRNWVwATg0oj4N0mTyboITiLHzBxJF5O9J4YOHdpi+83MrHzldJ39iKxPeR3Z2cxZwGPtedGIOKmZ1/sxWUo1ZFPf/Cjdb09mTn1zmTkRcTNwM0BNTY271czMKqicrrN+QE/gZbI/0hvSBWJ5eZ5szZsHgQ+TLR8NWZbNHZK+Q5YMUMjM2ZbmXzsBeJgsM+e7RftMAR7CmTlm1g7Dps1rsm7tzI92YEu6nrKzziQNB04B/ltSz4gY0vyebfbXwI3pDORNUpeWM3PMzLqmcrrOTgP+Avgg0Ad4gKwLLRcR8StgdBN1zswxM+tiyuk6+wjZXGc3RkRuF2qamVn3VM4yAZeQpRUfDSBpP0ltzjgzM7M9SzmzN/812cWO/5SKhpBNR2NmZtaicuY6uwR4P/AqQEQ8DQzIs1FmZtZ9lBNo3oqItwsPUjaYU4TNzKws5QSaX0j6KrCfpFqyiyj/M99mmZlZd1FOoPkK2UJnT5DNNjsf+FqejTIzs+6j2fRmST2A30bEMWQLNZmZmbVKs4EmIrZLelzS0Ij4Q0c1yszMus+0N+VcsDkIWClpKfBaobDxehpmZmallDNGcxVwGnA1cF3RzcxK2PrqesaPH8/w4cMZMWIEN954IwAbN26ktrYW4BhJCyX1KezjZcqtOytnUs2OWFXTrPvo0ZPrrruO4447jk2bNjF69Ghqa2u59dZbmTBhAosWLVoBLAamAV/xMuXW3ZVzRmNmrbBXr74cd9xxAPTu3Zvhw4fz3HPPMXfuXKZMmVLYbA7ZkuNQtEx5RDwDFJYpH0Rapjwtb/HjRvvMSfd/BkwonO2YVRsHGrMcrV27luXLlzN27FjWrVvHoEGDAIiIBnbOsLFjyfGksBz5YMpcphwoLFO+C0kXS1omadn69esr98bMWqGcZAAza4PNmzdz5plncsMNN3DAAQc0t2luy5R79dhdNZfFBV0rk6sraTLQSHqC0lPNCIiIODa3Vpl1cVu2bOHMM8/kk5/8JGeccQYAAwcOpKGhAYDULfZC2jy3ZcrNqkFzXWenAR8rcSuUt5mksyWtlLRdUk2juopl30iaIunpdJuCWQeICC688EKGDx/OZZddtqN80qRJzJlTGFZhCjA33b8XODcdy4ezc5nyBmCTpBPS8X5+o30Kx7SXKbeq1uQZTUQ8m+PrrgDOYOfSAwBUMvtGUl9gOlBDdmb2qKR7I+KlHN+XGW89t4rbfnIbI0eOZNSoUQB885vfZNq0aUyePBmy1WBfIa3+6mXKrbsrZynnE4DvAsOBvYGewGsR0Wync3Mi4sn03I2rdmTfAM+kL9EYSWtJ2Tdpv0L2zX1pnxlp/58Bs9Kvv1OAhRGxMe2zkCw43dnWdpuVY98hI2jq5GLx4sVIWhERE4rLvUy5VVK1jUWVk3U2CzgPeJrsV9VFZIEnD5XMvmnquXbjzBwzs/yUlXUWEasl9Uyn8/8i6Tct7SNpEXBIiaorI2JuiXKobPZNWVk54MwcM7M8lRNoXpe0N1An6VqgAdi/pZ0i4qQ2tKeS2Tf1wLhG+zzYhjaZWZXpLpNN7inK6Tr7dNruc2STah5GNpCfh0pm39wPnCypT5pT6uRUZmZmHaicQPOJiHgzIl6NiKsi4jKyFOc2k3S6pHrgRGCepPshy74BCtk3C9g9++ZHZNNzrGHX7Jt+KXHgMrL5o0hJAF8HHkm3qwuJAWZm1nHK6TqbAtzYqOyCEmVli4h7gHuaqKtY9k1EzAZmt7WdZmbWfs3NDHAe8JfA4ZLuLao6AHgx74aZmVn30NwZzW/IBv4PZtf1ZzYBv82zUWZm1n20NDPAs8CJkgYCx6eqJ9P1KmZmZi1qMRlA0tnAUrJxkMnAw5LOyrthZmbWPZSTDPA14PiIeAFAUn9gEdl0L2ZmZs0qJ725RyHIJC+WuZ+ZmVlZZzQL0nUuhckoz2HnNSxmZmbNajHQRMSXJZ0BfIBs/rCb03UwZmZt5mlk9hzlLBPwrYj4CvDvJcrMzMyaVc5YS22Jso9UuiFmZtY9NRloJE2V9ATwHkm/Lbo9gy/YNGvShvk3MGDAAI45ZueMSTNmzGDw4MGFFTePlnRqoa6Sy5ebVaPmzmjuAD5GNjvyx4puoyPiUx3QNrMuqdfIk1iwYMFu5Zdeeil1dXUAqyJiPuy2fPlE4PuSeqZdCsuXH5FuE1P5juXLgevJli83q1pNBpqIeCUi1kbEeRHxbNHNMyCbNWPfw46hb9++5W6+Y/nyiHiGbHbyMZIGkZYvT8teFJYvL+wzJ93/GTChcLZjVo18PYxZB5k1axbHHnsswLC0RhJUdvlys6rkQGPWAaZOncqaNWsKXWdb2DlRbSWXL9+NpIslLZO0bP369a1rtFmFdEqgkXS2pJWStkuqKSqvlfRoGgB9VNKHi+paPTAqaYqkp9NtCmadZODAgfTs2ZMePXoArAfGpKr2LF9Oo+XLdxMRN0dETUTU9O/fv0Lvxqx1OuuMZgXZctC/bFS+AfhYRIwkW3DttqK6Vg2MSuoLTAfGkn2ppxd1V5h1qIaGhuKHB5F9B6Cyy5ebVaVypqCpuIh4EqDx+GVELC96uBLYV9I+QF/SwGjarzAweh/ZwOiMtM/PgFnpi3kKsLCQvCBpIVlwuhOzHK2/91pOnPM7NmzYwJAhQ7jqqqt48MEHqaurKxzzBwCXQrZ8uaTC8uVb2X358luB/ciO9eLly29Ly5dvJMtaM6tanRJoynQmsDwi3pJU9sCopMLAaFODrGa56j/p8t2mULnwwgt33Je0Op2xAJVdvtysGuUWaCQtAg4pUXVlRMwtUV687wiyLrCTC0UlNmtpYLRVA6Zk3XIMHTq0uaaZmVkr5RZoIuKktuwnaQhwD3B+RKxJxeUMjNY3GhitB8Y12ufBJtp6M3AzQE1Njfu6zcwqqKrSmyUdBMwDroiIXxfK2zgwej9wsqQ+KQng5FRmZmYdqLPSm0+XVA+cCMxL690AfA54N/D3kurSbUCqmwr8iOzK6TXsOjDaLw2MXgZMA0hJAF8HHkm3qz2rgZlZx+usrLN7yLrHGpd/A/hGE/u0emA0ImYDs9vVWDMza5eq6jozM7Pux4HGzMxy5UBjZma5cqAxM7NcOdCYmVmuHGjMzCxXDjRmZpYrBxozM8uVA42ZmeXKgcbMzHLlQGNmZrlyoDGrsA3zb2DAgAEcc8zOqfk2btxIbW0tRxxxBMARxcuKS7pC0mpJT0k6pah8tKQnUt1NaeZy0rLPd6fyhyUN67h3Z9Z6DjRmFdZr5EksWLBgl7KZM2cyYcIEnn76aYBNpFnGJR1NthTzCLKlxr8vqWfa7QdkC/IdkW4TU/mFwEsR8W7gerJFAs2qlgONWYXte9gx9O3bd5eyuXPnMmVKYdkkXgQ+ke5/HLgrIt6KiGfIlsEYI2kQcEBEPJTWV/pxo33mpPs/AyYUznbMqpEDjVkHWLduHYMGDSo83AIU1lkaDPyxaNP6VDY43W9cvss+EbEVeAXol0vDzSrAgcasc5U6E4lmypvbZ/cnly6WtEzSsvXr17exiWbt01krbJ4taaWk7ZJqStQPlbRZ0peKylo9MCppiqSn021K49cx6ygDBw6koaGh8PAdwAvpfj1wWNGmQ4DnU/mQEuW77CNpL+BAoOTqsRFxc0TURERN//79K/BOzFqvs85oVgBnAL9sov56di7VXNCqgVFJfYHpwFhgDDC9ONPHrCNNmjSJOXMKwyr0A+am+/cC56YfTIeTHdtLI6IB2CTphPSj6vxG+xR+OJ0FPJDGccyqUqcEmoh4MiKeKlUn6RPA74GVRWVtGRg9BVgYERsj4iVgITuDk1lu1t97LSeeeCJPPfUUQ4YM4ZZbbmHatGksXLiwkN58ADATICJWAj8FVgELgEsiYlt6qqnAj8gSBNaw88fXLUA/SauBy0gZbGbVaq/ObkAxSfsDXwFqgS8VVZU9MCqpMDDa1CBrqde9mOxsiaFDh7b7fdierf+ky1k786O7lS9evBgASb+LiB1dXRFxDXBN4+0jYhlwTInyN4GzK9hks1zldkYjaZGkFSVuH29mt6uA6yNic+OnK7FtSwOjZQ+Yuh/bzCw/uZ3RRMRJbdhtLHCWpGuBg4Dtkt4E/o2WB0brGw2M1gPjGu3zYBvaZGZm7VBV6c0R8RcRMSwihgE3AN+MiFltHBi9HzhZUp+UBHByKjMzsw7UKWM0kk4Hvgv0B+ZJqouIU1rYbSpwK7Af2aBo8cDobWlgdCPZdB5ExEZJXwceSdtdXdwvbmZmHaNTAk1E3APc08I2Mxo9bvXAaETMBma3uaFmZtZuVdV1ZmZm3Y8DjZmZ5cqBxszMcuVAY2ZmuXKgMTOzXDnQmJlZrqpqrrNqV2r+Kut8/n8xq24+ozEzs1w50JiZWa7cdVbl3C1kZl2dz2jMzCxXDjRmZpYrd511EHeBVaeO/n8ZNmwYwNGS6oCtEVEjqS9wNzAMWAtMTsuPI+kK4EJgG/D5iLg/lY9m52zm84EvpOUxzKqOA41VlANqWX4XEaOKHk8DFkfETEnT0uOvSDqabNmLEcChwCJJR0bENuAHZMuPLyELNBPZuXSGWVVx15lZ5/s4MCfdnwN8oqj8roh4KyKeAVYDYyQNAg6IiIfSWcyPi/YxqzoONGYdKFsgliMkPSrp4lQ8MK0iS/p3QCofDPyxaPf6VDY43W9cXur1Lpa0TNKy9evXV+6NmLVCpwQaSWdLWilpu6SaRnXHSnoo1T8had9UPjo9Xi3pprSkM5L2kXR3Kn9Y0rCi55oi6el0m4JZJ/v1r38N8CTwEeASSR9sZnOVKItmyncvjLg5ImoioqZ///6tba5ZRXTWGc0K4Azgl8WFkvYCbgc+GxEjgHHAllRd6JM+It0mpvILgZci4t3A9cC30nP1BaYDY4ExwHRJffJ7S2YtO/TQQwGIiBfIVpkdA6xL3WGkf19Im9cDhxXtPgR4PpUPKVFuVpU6aynnJ2FHN0Kxk4HfRsTjabsX03Y7+qTT40Kf9H1k/dgz0v4/A2als51TgIURsTHts5AsON2Z1/uqNu0ZmPegfuW99tprbN++HQBJ+5Md71cD9wJTgJnp37lpl3uBOyR9hywZ4AhgaURsk7RJ0gnAw8D5wHc78r2YtUa1jdEcCYSk+yU9JunyVN5cn/SOfuyI2Aq8AvSj6f7t3bgf2zrCunXr+MAHPgBwNLAUmBcRC8gCTK2kp4Ha9JiIWAn8FFgFLAAuSRlnAFOBH5ElCKzBGWdWxXI7o5G0CDikRNWVETG3RHmhPR8AjgdeBxZLehR4tcS2hT7pivRjAzcD1NTU+FoEy8W73vUuHn/8cSStiogdY5PpzH1CqX0i4hrgmhLly4BjcmusWQXlFmgi4qQ27FYP/CIiNgBImg8cRzZu01SfdKEfuz6N8RwIbEzl4xrt82Ab2mRmZu1QbV1n9wPHSvqzFDQ+BKxKKZ+bJJ2Qxl/OZ9d+7EJG2VnAA+nagvuBkyX1SUkAJ6cyMzPrQJ2SDCDpdLLBy/7APEl1EXFKRLyUBj4fIevmmh8R89JuU9k55cZ97OyTvgW4TdJqsjOZcwEiYqOkr6fnAri6kBhg1ckJCGbdU2dlnd1DltpZqu52sq6yxuUl+6Qj4k3g7CaeazYwu12NNTOzdqm2rjMzM+tmHGjMzCxXDjRmZpYrBxozM8uV16MxawNnyJmVz2c0ZmaWKwcaMzPLlQONmZnlyoHGzMxy5UBjZma5cqAxM7NcOdCYmVmuHGjMuihJEyU9JWm1pGmd3R6zpjjQmHVBknoC3wM+QrY09HmSju7cVpmV5kBj1jWNAVZHxO8j4m3gLuDjndwms5KULUZpBZLWA8+WufnBwIYcm9Na1dYeqL42VUN73hkR/dvzBJLOAiZGxEXp8aeBsRHxuUbbXQxcnB6+B3iqzJeohs+pmNvTss5uU5PHtec6a6Q1fwAkLYuImjzb0xrV1h6ovjZVW3vaQSXKdvvVGBE3Aze3+smr7HNye1pWjW0qcNeZWddUDxxW9HgI8HwntcWsWQ40Zl3TI8ARkg6XtDdwLnBvJ7fJrCR3nbVPq7skclZt7YHqa1O1tadNImKrpM8B9wM9gdkRsbKCL1Ftn5Pb07JqbBPgZAAzM8uZu87MzCxXDjRmZpYrB5oytDTVhzI3pfrfSjoux7YcJum/JT0paaWkL5TYZpykVyTVpdv/y6s9Ra+5VtIT6fWWlajvyM/oPUXvvU7Sq5K+2GibDv+Mqk01Hdfp9aru2K6m4zq9Xtc8tiPCt2ZuZAOta4B3AXsDjwNHN9rmVOA+smsbTgAezrE9g4Dj0v3ewO9KtGcc8F8d/DmtBQ5upr7DPqMS/39/IruYrFM/o2q6VdtxnV6v6o7taj2ui/4Pu8Sx7TOalpUz1cfHgR9HZglwkKRBeTQmIhoi4rF0fxPwJDA4j9eqsA77jBqZAKyJiHJne9hTVNVxDV322O6s4xq60LHtQNOywcAfix7Xs/vBX842FSdpGPA+4OES1SdKelzSfZJG5N0WsqvSfy7p0TTtSWOd8hmRXV9yZxN1Hf0ZVZOqPa6hqo7taj2uoQsd276OpmXlTPVR1nQglSSpF/BvwBcj4tVG1Y+RnU5vlnQq8B/AEXm2B3h/RDwvaQCwUNL/RsQvi5tcYp+8P6O9gUnAFSWqO+MzqiZVeVxD1R3bVXdcQ9c7tn1G07Jypvro0OlAJL2D7Iv4k4j498b1EfFqRGxO9+cD75B0cF7tSa/zfPr3BeAesq6ZYp0xZcpHgMciYl3jis74jKpM1R3XUH3HdpUe19DFjm0HmpaVM9XHvcD5KQPlBOCViGjIozGSBNwCPBkR32lim0PSdkgaQ/b//GIe7Umvsb+k3oX7wMnAikabddhnVOQ8muha6OjPqApV1XEN1XdsV/FxDV3s2HbXWQuiiak+JH021f8QmE+WfbIaeB34TI5Nej/waeAJSXWp7KvA0KL2nAVMlbQVeAM4N1I6Sk4GAvekY3sv4I6IWNCJnxGS/gyoBf6mqKy4PR39GVWVKjyuofqO7ao7rqFrHtuegsbMzHLlrjMzM8uVA42ZmeXKgcbMzHLlQGNmZrlyoDEzs1w50JjZHkHS1ZJOqsDzbG7jfn8j6QJJoyT9sL3t6Eqc3mxm1gqSNkdErzbsdzswHTgN2BARP6l446qUz2jMrEuS9ClJS9OaK/8kqWcq3yzpOkmPSVosqX8qv1XSWen+TEmrlK0h8+1U9s60/W/Tv0NT+eGSHpL0iKSvN2rDl1P5byVd1UQ7L00XoJ5ONr3OVcCVe9JZjQONmXU5koYD55BNejkK2AZ8MlXvTzYP2HHAL8jOIor37Uv2R39ERBwLfCNVzSKb8v9Y4CfATan8RuAHEXE82fovhec5mWyyyjHAKGC0pA82bmtEXE92Jf/i1NanI+LoiPhsez6DrsSBxsy6ognAaOCRdLYwgWwRN4DtwN3p/u3ABxrt+yrwJvAjSWeQTR0DcCJwR7p/W9F+72fnvGK3FT3Pyem2nGzG5KNoepbk44DH09xpL5X1DrsRz3VmZl2RgDkRUWqa/MZ2GYhO87yNIQtO5wKfAz7cwn6lBrMF/ENE/FOTjcyWF/g5MIAsuJ0H9E7B8cyIWFNG+7s8n9GYWVe0GDgr/SFHUl9J70x1PcgmlgT4S+BXxTsqW+/mwDSF/hfJur0AfkMWeCDrhivs9+tG5QX3A3+Vng9JgwvtKYiIF1J32WNkXWy3A5+JiFF7SpABn9GYWRcUEaskfY1s9csewBbgEuBZ4DVghKRHgVfIxnKK9QbmStqX7Kzk0lT+eWC2pC8D69k5E/MXgDskfYFsML/Qhp+nsaKH0gzPm4FPAS8Uv1hKUugXERsk/TlQcgmE7szpzWbWrbQ1/djy464zMzPLlc9ozMwsVz6jMTOzXDnQmJlZrhxozMwsVw40ZmaWKwcaMzPL1f8HNw6eVpp7qEoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing RL agent which randomly chooses actions\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import gym\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05')\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_1 = []\n",
    "off_line_rewards_lst_1 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    ob = env.reset(seed=i)\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "\n",
    "    while not done:\n",
    "        # random action as policy\n",
    "        action = env.action_space.sample()\n",
    "        # print(\"step: \", env.count)\n",
    "        # print(\"charging costs: \", env.bats_charge_costs)\n",
    "        # print(\"discharging costs: \", env.bats_discharge_costs)\n",
    "        # print(\"env load: \", env.load_demand)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    # print(\"episode {} mean reward: {}\".format(i, np.mean(rewards)))\n",
    "    rewards_lst_1.append(np.sum(rewards))\n",
    "    ob = env.reset(seed=i)\n",
    "    off_line_rewards_lst_1.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(list(range(episodes)), rewards_lst_1, width=0.5)\n",
    "plt.title(\"Random Actions\")\n",
    "\n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "# plot episode # versus total offline episode reward\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(list(range(episodes)), off_line_rewards_lst_1, width=0.5)\n",
    "plt.title(\"Offline Optimal\")\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.70s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "# env = BatteryStorageInGridEnv(date='2019-05')\n",
    "\n",
    "# stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "# eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "# model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "# model.learn(int(1e10), callback=eval_callback)\n",
    "# model.save(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_4 = []\n",
    "off_line_rewards_lst_4 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i)\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_4.append(np.sum(rewards))\n",
    "    ob = env.reset(seed=i)\n",
    "    off_line_rewards_lst_4.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(list(range(episodes)), rewards_lst_4, width=0.5)\n",
    "plt.title(\"Random Actions\")\n",
    "\n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "# plot episode # versus total offline episode reward\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(list(range(episodes)), off_line_rewards_lst_4, width=0.5)\n",
    "plt.title(\"Offline Optimal\")\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000004vscode-remote?line=14'>15</a>\u001b[0m \u001b[39m# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000004vscode-remote?line=15'>16</a>\u001b[0m model \u001b[39m=\u001b[39m DDPG(\u001b[39m\"\u001b[39m\u001b[39mMultiInputPolicy\u001b[39m\u001b[39m\"\u001b[39m, env, action_noise\u001b[39m=\u001b[39maction_noise, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000004vscode-remote?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(\u001b[39mint\u001b[39;49m(\u001b[39m1e10\u001b[39;49m), callback\u001b[39m=\u001b[39;49meval_callback)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000004vscode-remote?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mddpg_single_agent_battery_env\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000004vscode-remote?line=19'>20</a>\u001b[0m \u001b[39m# del model # remove to demonstrate saving and loading\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py:130\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    118\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    119\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    128\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    131\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    132\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    133\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    134\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    135\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    136\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    137\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    138\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    139\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    140\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/td3/td3.py:211\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    200\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    212\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    213\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    214\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    215\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    216\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    217\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    218\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    219\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    220\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:346\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    343\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    345\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 346\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    347\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    348\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    349\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    350\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    351\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    352\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    353\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    354\u001b[0m     )\n\u001b[1;32m    356\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:579\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    576\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[1;32m    578\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m    581\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    582\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx][\u001b[39m\"\u001b[39m\u001b[39mterminal_observation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m obs\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/monitor.py:90\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/sustaingym/sustaingym/tests/../envs/MO_single_agent_battery_storage_env.py:462\u001b[0m, in \u001b[0;36mBatteryStorageInGridEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit\n\u001b[1;32m    461\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_type \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 462\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mcontains(action)\n\u001b[1;32m    464\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    466\u001b[0m \u001b[39m# ensure selling cost (a) for charge is at least as large as buying cost (b)\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3.ddpg.policies import MultiInputPolicy\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3 import DDPG\n",
    "import numpy as np\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05')\n",
    "\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# model = DDPG(MultiInputPolicy, env, action_noise=action_noise, verbose=1)\n",
    "model = DDPG(\"MultiInputPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(int(1e10), callback=eval_callback)\n",
    "model.save(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_2 = []\n",
    "off_line_rewards_lst_2 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i)\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_2.append(np.sum(rewards))\n",
    "    ob = env.reset(seed=i)\n",
    "    off_line_rewards_lst_2.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(list(range(episodes)), rewards_lst_2, width=0.5)\n",
    "plt.title(\"Random Actions\")\n",
    "\n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "# plot episode # versus total offline episode reward\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(list(range(episodes)), off_line_rewards_lst_2, width=0.5)\n",
    "plt.title(\"Offline Optimal\")\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 287      |\n",
      "|    ep_rew_mean        | 2.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 209      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | -24.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0143  |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.07e-05 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1000, episode_reward=2409.92 +/- 74.85\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.41e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -1.13    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.0393   |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 0.000208 |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 287      |\n",
      "|    ep_rew_mean     | 2.5e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 200      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 1000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 322      |\n",
      "|    ep_rew_mean        | 3.13e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -5.55    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.014    |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 6.81e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=2575.21 +/- 170.36\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.58e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | 0.105    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.00405 |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 1.11e-05 |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 310      |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 400      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 2000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | 3.15e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -0.133   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.0408   |\n",
      "|    std                | 0.995    |\n",
      "|    value_loss         | 0.0003   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=2389.82 +/- 72.68\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.39e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.82    |\n",
      "|    explained_variance | -9.92    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.00152  |\n",
      "|    std                | 0.99     |\n",
      "|    value_loss         | 2.03e-05 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 318      |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 600      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 3000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 329      |\n",
      "|    ep_rew_mean        | 3.16e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.82    |\n",
      "|    explained_variance | -10.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.00836 |\n",
      "|    std                | 0.993    |\n",
      "|    value_loss         | 4.37e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=2420.96 +/- 121.50\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.42e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.81    |\n",
      "|    explained_variance | -2.85    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.0161  |\n",
      "|    std                | 0.988    |\n",
      "|    value_loss         | 5.22e-05 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 322      |\n",
      "|    ep_rew_mean     | 3.06e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 800      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 4000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 330      |\n",
      "|    ep_rew_mean        | 3.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -4.68    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.0241   |\n",
      "|    std                | 0.995    |\n",
      "|    value_loss         | 0.000149 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=2647.75 +/- 131.91\n",
      "Episode length: 287.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 287       |\n",
      "|    mean_reward        | 2.65e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.83     |\n",
      "|    explained_variance | -1.65e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -0.00385  |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 2.84e-06  |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 324      |\n",
      "|    ep_rew_mean     | 3.11e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 5000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 330      |\n",
      "|    ep_rew_mean        | 3.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | -60.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.0194  |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.69e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=2486.03 +/- 110.32\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.49e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | -59.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.00691 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.00012  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 326      |\n",
      "|    ep_rew_mean     | 3.17e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 1200     |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 6000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 331      |\n",
      "|    ep_rew_mean        | 3.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.646   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.0219  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.92e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=2426.43 +/- 60.56\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.43e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -0.0437  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.0192   |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 3.9e-05  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | 3.19e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 1400     |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 7000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 331      |\n",
      "|    ep_rew_mean        | 3.28e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | 0.0276   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.00426 |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 3.72e-06 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=2424.62 +/- 146.32\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.42e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | 0.363    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.013   |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.62e-05 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 328      |\n",
      "|    ep_rew_mean     | 3.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 1600     |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 8000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 331      |\n",
      "|    ep_rew_mean        | 3.29e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | -3.84    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.0104   |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.28e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=2547.32 +/- 138.80\n",
      "Episode length: 287.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 287      |\n",
      "|    mean_reward        | 2.55e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -0.275   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.0194   |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 8.57e-05 |\n",
      "------------------------------------\n",
      "Stopping training because there was no new best model in the last 4 evaluations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.78s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05')\n",
    "\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "model = A2C(\"MultiInputPolicy\", env, verbose=1)\n",
    "model.learn(int(1e10), callback=eval_callback)\n",
    "model.save(\"a2c_single_agent_battery_env\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"a2c_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_3 = []\n",
    "off_line_rewards_lst_3 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i)\n",
    "    done = False\n",
    "    start = True\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    avg = np.zeros(1)\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_lst_3.append(np.sum(rewards))\n",
    "    ob = env.reset(seed=i)\n",
    "    off_line_rewards_lst_3.append(env._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "# plot episode # versus total episode reward\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(list(range(episodes)), rewards_lst_3, width=0.5)\n",
    "plt.title(\"Random Actions\")\n",
    "\n",
    "# naming the y axis \n",
    "plt.ylabel('total reward')\n",
    "\n",
    "# plot episode # versus total offline episode reward\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(list(range(episodes)), off_line_rewards_lst_3, width=0.5)\n",
    "plt.title(\"Offline Optimal\")\n",
    "\n",
    "# naming the x axis \n",
    "plt.xlabel('episode #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:08<00:19,  2.72s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (1, 2)) of distribution Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan]], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000006vscode-remote?line=17'>18</a>\u001b[0m rewards \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(env1\u001b[39m.\u001b[39mMAX_STEPS_PER_EPISODE)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000006vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000006vscode-remote?line=19'>20</a>\u001b[0m     action, _states \u001b[39m=\u001b[39m model_ppo\u001b[39m.\u001b[39;49mpredict(obs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000006vscode-remote?line=20'>21</a>\u001b[0m     \u001b[39mif\u001b[39;00m action\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-3-142-99-116.us-east-2.compute.amazonaws.com/home/ubuntu/sustaingym/sustaingym/tests/single_agent_env_tests.ipynb#ch0000006vscode-remote?line=21'>22</a>\u001b[0m         action \u001b[39m=\u001b[39m action\u001b[39m.\u001b[39mreshape((\u001b[39m2\u001b[39m,))\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/base_class.py:579\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    561\u001b[0m     observation: np\u001b[39m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    564\u001b[0m     deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    565\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, Optional[Tuple[np\u001b[39m.\u001b[39mndarray, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]]:\n\u001b[1;32m    566\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mpredict(observation, state, episode_start, deterministic)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/policies.py:338\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    335\u001b[0m observation, vectorized_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_to_tensor(observation)\n\u001b[1;32m    337\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 338\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(observation, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[1;32m    339\u001b[0m \u001b[39m# Convert to numpy\u001b[39;00m\n\u001b[1;32m    340\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/policies.py:630\u001b[0m, in \u001b[0;36mActorCriticPolicy._predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, observation: th\u001b[39m.\u001b[39mTensor, deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    623\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[39m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_distribution(observation)\u001b[39m.\u001b[39mget_actions(deterministic\u001b[39m=\u001b[39mdeterministic)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/policies.py:659\u001b[0m, in \u001b[0;36mActorCriticPolicy.get_distribution\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    657\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs)\n\u001b[1;32m    658\u001b[0m latent_pi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_extractor\u001b[39m.\u001b[39mforward_actor(features)\n\u001b[0;32m--> 659\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_action_dist_from_latent(latent_pi)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/policies.py:607\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    604\u001b[0m mean_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_net(latent_pi)\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[0;32m--> 607\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_dist\u001b[39m.\u001b[39;49mproba_distribution(mean_actions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_std)\n\u001b[1;32m    608\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[1;32m    609\u001b[0m     \u001b[39m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[1;32m    610\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist\u001b[39m.\u001b[39mproba_distribution(action_logits\u001b[39m=\u001b[39mmean_actions)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/stable_baselines3/common/distributions.py:153\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m:return:\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m action_std \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mones_like(mean_actions) \u001b[39m*\u001b[39m log_std\u001b[39m.\u001b[39mexp()\n\u001b[0;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution \u001b[39m=\u001b[39m Normal(mean_actions, action_std)\n\u001b[1;32m    154\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/torch/distributions/normal.py:50\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     batch_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc\u001b[39m.\u001b[39msize()\n\u001b[0;32m---> 50\u001b[0m \u001b[39msuper\u001b[39;49m(Normal, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(batch_shape, validate_args\u001b[39m=\u001b[39;49mvalidate_args)\n",
      "File \u001b[0;32m~/.conda/envs/sustaingym/lib/python3.9/site-packages/torch/distributions/distribution.py:55\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m         valid \u001b[39m=\u001b[39m constraint\u001b[39m.\u001b[39mcheck(value)\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid\u001b[39m.\u001b[39mall():\n\u001b[0;32m---> 55\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected parameter \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof distribution \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mto satisfy the constraint \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(constraint)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found invalid values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[39msuper\u001b[39m(Distribution, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter loc (Tensor of shape (1, 2)) of distribution Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan]], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "# Get rewards for Testing on May 2021\n",
    "\n",
    "model_ppo = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "model_a2c = PPO.load(\"a2c_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_lst_ppo_21_5 = []\n",
    "rewards_lst_a2c_21_5 = []\n",
    "off_line_rewards_lst_21_5 = []\n",
    "\n",
    "env1 = BatteryStorageInGridEnv(date='2021-05')\n",
    "env2 = BatteryStorageInGridEnv(date='2021-05')\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env1.reset(seed=i)\n",
    "    done = False\n",
    "    rewards = np.zeros(env1.MAX_STEPS_PER_EPISODE)\n",
    "    while not done:\n",
    "        action, _states = model_ppo.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env1.step(action)\n",
    "        rewards[env1.count - 1] = reward\n",
    "    \n",
    "    obs2 = env2.reset(seed=i)\n",
    "    done2 = False\n",
    "    rewards2 = np.zeros(env2.MAX_STEPS_PER_EPISODE)\n",
    "    while not done2:\n",
    "        action, _states = model_a2c.predict(obs2)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs2, reward, done2, info = env2.step(action)\n",
    "        rewards2[env2.count - 1] = reward\n",
    "    rewards_lst_ppo_21_5.append(np.sum(rewards))\n",
    "    rewards_lst_a2c_21_5.append(np.sum(rewards2))\n",
    "    ob = env1.reset(seed=i)\n",
    "    off_line_rewards_lst_21_5.append(env1._calculate_off_optimal_total_episode_reward())\n",
    "\n",
    "print(\"2021/5 PPO: \", rewards_lst_ppo_21_5)\n",
    "print(\"2021/5 A2C: \", rewards_lst_a2c_21_5)\n",
    "print(\"2021/5 Offline Optimal: \", off_line_rewards_lst_21_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate evaluation for PPO trained on May 2019 and tested on May 2019 (in-dist)\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05', seed=195)\n",
    "\n",
    "model_ppo = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_ppo_19_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    while not done:\n",
    "        action, _states = model_ppo.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_ppo_19_5.append(np.sum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate evaluation for A2C trained on May 2019 and tested on May 2019 (in-dist)\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05', seed=195)\n",
    "\n",
    "model_a2c = A2C.load(\"a2c_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_a2c_19_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    while not done:\n",
    "        action, _states = model_a2c.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_a2c_19_5.append(np.sum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate off-line optimal values for May 2019\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2019-05', seed=195)\n",
    "\n",
    "offline_optimal_19_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    offline_optimal_19_5.append(env._calculate_off_optimal_total_episode_reward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate evaluation for PPO trained on May 2019 and tested on May 2021 (out-dist)\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2021-05', seed=215)\n",
    "\n",
    "model_ppo_out = PPO.load(\"ppo_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_ppo_21_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    while not done:\n",
    "        action, _states = model_ppo_out.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_ppo_21_5.append(np.sum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate evaluation for A2C trained on May 2019 and tested on May 2021 (out-dist)\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2021-05', seed=215)\n",
    "\n",
    "model_a2c_out = A2C.load(\"a2c_single_agent_battery_env\")\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "rewards_a2c_21_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    done = False\n",
    "    rewards = np.zeros(env.MAX_STEPS_PER_EPISODE)\n",
    "    while not done:\n",
    "        action, _states = model_a2c_out.predict(obs)\n",
    "        if action.shape[0] == 1:\n",
    "            action = action.reshape((2,))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        rewards[env.count - 1] = reward\n",
    "    rewards_a2c_21_5.append(np.sum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from tqdm import tqdm\n",
    "\n",
    "# generate off-line optimal values for May 2019\n",
    "\n",
    "env = BatteryStorageInGridEnv(date='2021-05', seed=215)\n",
    "\n",
    "offline_optimal_21_5 = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    obs = env.reset(seed=i*10)\n",
    "    offline_optimal_21_5.append(env._calculate_off_optimal_total_episode_reward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/5 PPO:  [2245.0145741723068, 2558.4557707267295, 2536.6470375887716, 2213.9489259221714, 2545.763597560765, 2602.458985199197, 2372.820422435832, 2548.4725186985274, 2261.2602848462757, 2779.4824376099523]\n",
      "2019/5 A2C:  [2245.0145743153016, 2558.4557716921063, 2536.647038219378, 2213.948927097822, 2545.763598501142, 2602.458988265422, 2372.82042346052, 2548.472526844007, 2261.2602856102226, 2779.4824385186284]\n",
      "2019/5 Offline Optimal:  [23051.710297436803, 18248.597237755643, 18994.697055206787, 22868.55334810844, 16514.00674815259, 33131.47019110864, 14612.253560855821, 22389.303426021896, 23079.613407532303, 23031.783863923756]\n",
      "2021/5 PPO:  [2743.0189450456783, 2609.6690354598877, 2641.4290383788198, 2714.706752567427, 2342.052034742505, 2732.207455008233, 2753.6307763219734, 2784.0557684839923, 2722.8755581028713, 2835.9102791492815]\n",
      "2021/5 A2C:  [2743.0189478052616, 2609.6690381383055, 2641.42903982744, 2714.7067542683335, 2342.0520677395284, 2732.207453737356, 2753.6307779419335, 2784.0557688661515, 2722.8755588359236, 2835.9102810094723]\n",
      "2021/5 Offline Optimal:  [20482.670758292246, 19429.36173842518, 16713.67791627479, 22916.353857972834, 18087.993419986706, 20595.192383295172, 17483.9390511944, 21319.578990298218, 22556.99662278885, 21071.943076509524]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"2019/5 PPO: \", rewards_ppo_19_5)\n",
    "print(\"2019/5 A2C: \", rewards_a2c_19_5)\n",
    "print(\"2019/5 Offline Optimal: \", offline_optimal_19_5)\n",
    "print(\"2021/5 PPO: \", rewards_ppo_21_5)\n",
    "print(\"2021/5 A2C: \", rewards_a2c_21_5)\n",
    "print(\"2021/5 Offline Optimal: \", offline_optimal_21_5)\n",
    "\n",
    "models = ['Offline', 'PPO', 'A2C']\n",
    "in_dist = [np.mean(offline_optimal_19_5), np.mean(rewards_ppo_19_5), np.mean(rewards_a2c_19_5)]\n",
    "out_dist = [np.mean(offline_optimal_21_5), np.mean(rewards_ppo_21_5), np.mean(rewards_a2c_21_5)]\n",
    "\n",
    "x_axis = np.arange(len(models))\n",
    "\n",
    "plt.bar(x_axis - 0.2, in_dist, width=0.4, label='In-Dist', color='blue')\n",
    "plt.bar(x_axis + 0.2, out_dist, width=0.4, label='Out-Dist', color='orange')\n",
    "\n",
    "in_dist_err = [np.std(offline_optimal_19_5), np.std(rewards_ppo_19_5), np.std(rewards_a2c_19_5)]\n",
    "out_dist_err = [np.std(offline_optimal_21_5), np.std(rewards_ppo_21_5), np.std(rewards_a2c_21_5)]\n",
    "\n",
    "plt.errorbar(x_axis - 0.2, in_dist, yerr=in_dist_err, fmt='o', color='gray')\n",
    "plt.errorbar(x_axis + 0.2, out_dist, yerr=out_dist_err, fmt='o', color='gray')\n",
    "\n",
    "plt.xticks(x_axis, models)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sustaingym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c910351b0c3a4aade2cf03b555240fe9951314ae7b50b4f56bc279231ceafe8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
